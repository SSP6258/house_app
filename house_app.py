import time
import pandas as pd
import numpy as np
import os
import datetime
import streamlit as st
import plotly.graph_objs as go
import plotly.express as px
import xgboost as xgb
import pickle
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.mixture import GaussianMixture
from plotly.subplots import make_subplots
from treeinterpreter import treeinterpreter
from waterfall_chart import plot as waterfall
from st_aggrid import AgGrid
from PIL import Image
from collections import defaultdict
from dataprep.eda import plot_correlation
from house_utils import fn_get_geo_info, fn_get_admin_dist, dic_of_path, geodesic
from house_elt import fn_addr_handle, fn_house_coor_read, fn_house_coor_save
from house_elt import fn_gen_build_case, fn_gen_house_data

# pip list --format=freeze > requirements.txt

dic_of_cn_2_en = {'ç¶“åº¦': 'longitude',
                  'ç·¯åº¦': 'latitude',
                  'ç§»è½‰å±¤æ¬¡': 'Floor',
                  'è»Šä½é¡åˆ¥_å…¶ä»–': 'p_other',
                  'è»Šä½é¡åˆ¥_å¡é“æ©Ÿæ¢°': 'p_ramp_machine',
                  'è»Šä½é¡åˆ¥_ä¸€æ¨“å¹³é¢': 'p_1f_plane',
                  'è»Šä½é¡åˆ¥_å¡é“å¹³é¢': 'p_ramp_plane',
                  'è»Šä½é¡åˆ¥_å‡é™æ©Ÿæ¢°': 'p_lift_machine',
                  'è»Šä½é¡åˆ¥_å¡”å¼è»Šä½': 'p_tower',
                  'è»Šä½é¡åˆ¥_å‡é™å¹³é¢': 'p_lift_plane',
                  'äº¤æ˜“å¹´': 'trade_year',
                  'ç¸½æ¨“å±¤æ•¸': 'Floors',
                  'é ‚æ¨“': 'roof',
                  'é ‚æ¨“-1': 'roof-1',
                  'å°åŒ—å¸‚': 'TPE',
                  'å±‹é½¡': 'Age',
                  'ä¸»è¦å»ºæ_RC': 'RC',
                  'ä¸»è¦å»ºæ_SRC': 'SRC',
                  'ä¸»è¦å»ºæ_SC': 'SC',
                  'å»ºç‰©åªæ•¸': 'building acreage',
                  'è»Šä½åªæ•¸': 'parking acreage',
                  'å¹¾å»³': 'livingrooms',
                  'å¹¾è¡›': 'bathrooms',
                  'å¹¾æˆ¿': 'rooms',
                  'åˆ©ç‡_15å€‹æœˆå‰': 'interest rate(15M ago)',
                  'åˆ©ç‡_13å€‹æœˆå‰': 'interest rate(13M ago)',
                  'ä½¿ç”¨åˆ†å€_ä½': 'land_typ'
                  }


def fn_show_img(IMG_path, IMG_file):
    png = os.path.join(IMG_path, IMG_file)
    img = Image.open(png)
    st.image(img)


def fn_addr_2_house_num(x):
    num = x.split('è·¯')[-1]
    num = num.split('è¡—')[-1]
    num = num.split('æ®µ')[-1]
    num = num.split('å··')[-1]
    num = num.split('å¼„')[-1]

    if num == x:
        print(x, 'special addr !!!')

    return num


def fn_addr_2_build_case(addr):
    build_case = 'No_build _case_found'
    build_case_str = 'NA'
    df_coor_read = fn_house_coor_read()
    addr = fn_addr_handle(addr)

    if addr in df_coor_read.index:
        build_case_str = str(df_coor_read.loc[addr, 'Build case'])

    if build_case == 'No_build_case_found':
        geo, is_save, is_match, addr_fr_db = fn_get_geo_info(addr, df_coor_read)
        lat = geo['coor']['lat']
        lon = geo['coor']['log']
        print(lat, lon, addr)
        df_sel = df_coor_read[df_coor_read['lat'].apply(lambda x: abs(x - lat) < 0.00001)]
        df_sel = df_sel[df_sel['lon'].apply(lambda x: abs(x - lon) < 0.00001)]
        df_sel = df_sel[df_sel['Build case'].apply(lambda x: str(x) not in ['nan', 'NA'])]
        if df_sel.shape[0]:
            builds = df_sel['Build case'].unique()
            build_case_str = builds[0]
            if len(builds) > 1:
                print(df_sel['Build case'].unique())

    if build_case_str != 'nan' and build_case_str != 'NA' and not build_case_str.endswith('å€'):
        build_case = build_case_str
        print(addr, '-->', build_case)

    return build_case


# Anomaly Detection using Gaussian Mixtures
def fn_anomaly_detection(df, n_comp, percent):
    df_det = df[['MRT_DIST', 'ç¸½æ¨“å±¤æ•¸', 'ç§»è½‰å±¤æ¬¡', 'lat', 'log', 'æ¯åªå–®åƒ¹(è¬)']]

    n_comp = int(df.shape[0] / 2) if df.shape[0] < n_comp else n_comp

    gm = GaussianMixture(n_components=n_comp, n_init=10, random_state=42)
    gm.fit(df_det)
    densities = gm.score_samples(df_det)
    density_threshold = np.percentile(densities, percent)
    anomalies = df_det[densities < density_threshold]
    df['ano'] = densities < density_threshold

    return df


def fn_cln_house_data(df):
    df['city'] = df['åœŸåœ°ä½ç½®å»ºç‰©é–€ç‰Œ'].apply(lambda x: x.split('å¸‚')[0].replace('è‡º', 'å°') + 'å¸‚')
    df['å»ºç‰©ç§»è½‰åªæ•¸'] = df['å»ºç‰©ç§»è½‰åªæ•¸'].apply(lambda x: round(x, 2))
    df['å»ºç‰©å‹æ…‹'] = df['å»ºç‰©å‹æ…‹'].apply(lambda x: 'è¯å»ˆ' if 'è¯å»ˆ' in x else 'å¤§æ¨“' if 'å¤§æ¨“' in x else x)
    df.rename(columns={col: col.replace('ç§»è½‰åªæ•¸', 'åªæ•¸') for col in df.columns}, inplace=True)
    df = df[df['è»Šä½ç¸½åƒ¹å…ƒ'].astype(float) > 0] if 'è»Šä½ç¸½åƒ¹å…ƒ' in df.columns else df
    df = fn_gen_build_case(df)
    df[['ç¶“åº¦', 'ç·¯åº¦']] = df[['log', 'lat']]

    return df


@st.cache(allow_output_mutation=True)
def fn_load_model(model_sel):
    try:
        loaded_model = pickle.load(open(model_sel, 'rb'))
    except:
        assert False, f'fn_load_model() fail, from {model_sel}'

    return loaded_model


def fn_set_radio_2_hor():
    st.write('<style>div.row-widget.stRadio > div{flex-direction:row;}</style>', unsafe_allow_html=True)


def fn_set_color_by(by, df):
    color_set = None
    opacity = 0.3

    if by == 'ä¾æ·é‹è·é›¢':
        color_set = df['MRT_DIST']
    elif by == 'ä¾é€šå‹¤æ™‚é–“':
        color_set = df['MRT_Commute_Time_UL']
    elif by == 'ä¾äº¤æ˜“å¹´':
        color_set = df['äº¤æ˜“å¹´']
    elif by == 'ä¾å°å­¸è·é›¢':
        color_set = df['sku_dist']
    elif by == 'ä¾å°å­¸äººæ•¸':
        color_set = df['sku_109_total']
    elif by == 'ä¾ç¸½æ¨“å±¤æ•¸':
        color_set = df['ç¸½æ¨“å±¤æ•¸']
    elif by == 'ä¾å»ºç‰©åªæ•¸':
        color_set = df['å»ºç‰©åªæ•¸']
    elif 'ä¾æœ€æ–°ç™»éŒ„' in by:
        color_set = df['Latest']
        opacity = 0.6
    elif 'ä¾è¡Œæ”¿å€' in by:
        label_encoder = LabelEncoder()
        color_set = label_encoder.fit_transform(df['é„‰é®å¸‚å€'])

    return color_set, opacity


@st.cache
def fn_get_house_data(path):
    df = pd.read_csv(path)
    read_typ = path.replace('\\', '/').split('/')[-3]
    is_merge_pre_own = False

    if read_typ == 'pre_sold_house' and is_merge_pre_own:
        pre_ownd_path = path.replace('pre_sold_house', 'pre_owned house')
        df.drop(columns=['æ£ŸåŠè™Ÿ'], inplace=True)
        if os.path.exists(pre_ownd_path):
            df_ownd = pd.read_csv(pre_ownd_path)
            df_ownd = df_ownd[df_ownd['å±‹é½¡'] == 0]

            df_ownd['å»ºç¯‰å®Œæˆå¹´æœˆ'] = df_ownd['å»ºç¯‰å®Œæˆå¹´æœˆ'].apply(lambda x: np.nan)
            if df_ownd.shape[0]:
                col_sold = df.columns
                col_ownd = df_ownd.columns
                col_drop = []
                for c in col_ownd:
                    if c not in col_sold:
                        col_drop.append(c)
                df_ownd.drop(columns=col_drop, inplace=True)
                df = df.append(df_ownd)
                # df.drop_duplicates(subset=['åœ°å€', 'äº¤æ˜“å¹´æœˆæ—¥', 'ç¸½æ¨“å±¤æ•¸', 'ç§»è½‰å±¤æ¬¡', 'æ¯åªå–®åƒ¹(è¬)', 'å»ºç‰©ç§»è½‰åªæ•¸'],
                #                    inplace=True)
                # df.reset_index(drop=True, inplace=True)
                df.to_csv(path.replace('.csv', f'_add_{df_ownd.shape[0]}.csv'), encoding='utf-8-sig', index=False)
                print(f'Append {df_ownd.shape[0]} data from pre_ownd to {read_typ} and total is {df.shape[0]}')

    df.drop_duplicates(subset=['åœ°å€', 'äº¤æ˜“å¹´æœˆæ—¥', 'ç¸½æ¨“å±¤æ•¸', 'ç§»è½‰å±¤æ¬¡', 'æ¯åªå–®åƒ¹(è¬)', 'å»ºç‰©ç§»è½‰åªæ•¸'], inplace=True)
    df.reset_index(drop=True, inplace=True)
    print(f'Read {read_typ} data from {path} !!!')
    return df


def fn_get_neighbor(target, neighbors):
    neighbors = list(neighbors)
    path = dic_of_path['database']
    path_db = os.path.join(path, 'School_info.csv')
    df = pd.read_csv(path_db, encoding='utf-8-sig')
    coor_t = tuple(df[df['schoolname'] == target][['lat', 'lon']].values[0])

    distances = []
    for n in neighbors:
        coor_n = tuple(df[df['schoolname'] == n][['lat', 'lon']].values[0])
        distances.append(int(geodesic(coor_t, coor_n).meters))

    closest = neighbors[distances.index(min(distances))]

    st.write(f'é„°è¿‘å°å­¸: {target}, å‡åƒ¹åƒè€ƒ: {closest}')

    return closest


def fn_get_sku_people_by_year(df):
    path = dic_of_path['database']
    file = os.path.join(path, 'School_info.csv')
    columns = df.columns
    if 'äº¤æ˜“å¹´' in columns and 'sku_name' in columns:
        df_sku = pd.read_csv(file, encoding='utf-8-sig')
        for idx in df.index:
            year = df.loc[idx, 'äº¤æ˜“å¹´'] - 1
            school = df.loc[idx, 'sku_name']
            city = 'å°åŒ—å¸‚' if df.loc[idx, 'å°åŒ—å¸‚'] else 'æ–°åŒ—å¸‚'

            df_sku_sel = df_sku[df_sku['schoolname'] == school]
            df_sku_sel = df_sku_sel[df_sku_sel['city'] == city]
            assert df_sku_sel.shape[0] == 1, f'{city, school, df_sku_sel.shape[0]}'

            for y in range(10):
                year_total = f'{y + year}_Total'
                if year_total in df_sku_sel.columns:
                    total = df_sku_sel[year_total].values[0]

                if str(total) == 'nan':
                    if y:
                        print(f'can NOT find sku total of {city, school, total, year} try {year_total}')
                else:
                    break

            assert str(total) != 'nan', f'{idx, total, city, school, year_total, year}'
            df.at[idx, 'sku_total'] = total
    else:
        print(columns)

    return df


def fn_get_interest_rate(df, months=1):
    path = dic_of_path['database']
    file = os.path.join(path, 'a13rate.csv')
    df['äº¤æ˜“å¹´æœˆæ—¥'] = df['äº¤æ˜“å¹´'] * 10000 + 900 if 'äº¤æ˜“å¹´æœˆæ—¥' not in df.columns else df['äº¤æ˜“å¹´æœˆæ—¥']

    df_rate = pd.read_csv(file, encoding='utf-8-sig', header=4)
    rate_col = df_rate.columns[13]  # å®šå­˜åˆ©ç‡
    date_col = df_rate.columns[0]
    for idx in df.index:
        trade_date = float(int(df.loc[idx, 'äº¤æ˜“å¹´æœˆæ—¥'] / 100))

        if trade_date in df_rate[date_col].values:
            df_t = df_rate[df_rate[date_col] <= trade_date]
            rates = df_t[rate_col].values
            rate_sel = []
            for m in range(months):
                try:
                    rate_sel.append(rates[-1 - m])
                except:
                    rate_sel.append(rate_sel[-1])

                df.at[idx, f'åˆ©ç‡_{m}å€‹æœˆå‰'] = rate_sel[-1]
        else:
            assert False, f'can NOT find interest_rate of {trade_date}'

    return df


def fn_get_categories(path, feature):
    df_f = pd.read_csv(os.path.join(path, f'output\\Feature_{feature}.csv'))
    cats = df_f[feature].to_list()

    return cats


def fn_get_hover_text(df):
    txt = ''
    cols = df.columns

    if 'é„‰é®å¸‚å€' in cols:
        txt += df['é„‰é®å¸‚å€']

    if 'å»ºæ¡ˆåç¨±' in cols:
        txt += df['å»ºæ¡ˆåç¨±'].astype(str)

    if 'äº¤æ˜“å¹´' in cols:
        txt += df['äº¤æ˜“å¹´'].astype(str) + 'å¹´, '

    if 'MRT DIST' in cols:
        txt += df['MRT_DIST'].astype(int).astype(str) + 'å…¬å°º, '

    if 'MRT_Commute_Time_UL' in cols:
        txt += df['MRT_Commute_Time_UL'].astype(str) + 'åˆ†é˜'

    return txt


def fn_gen_pred(path, model, model_name, df_F, build_typ, is_rf):
    st.write('')
    st.subheader('æ‰¹æ¬¡é©—è­‰')
    st.write("é©—è­‰è³‡æ–™:[å†…æ”¿éƒ¨ä¸å‹•ç”¢æˆäº¤æ¡ˆä»¶ è³‡æ–™ä¾›æ‡‰ç³»çµ±(æ¯æœˆ1ã€11ã€21æ—¥ç™¼å¸ƒ)](https://plvr.land.moi.gov.tw/DownloadOpenData)")

    file = st.file_uploader("è³‡æ–™ä¸Šå‚³", type=['csv'])
    print(file)
    if not file:
        st.write(' please upload *.csv to test')
    else:
        df = pd.read_csv(file)
        ave_path = dic_of_path['database']
        df_sku_ave = pd.read_csv(os.path.join(ave_path, 'SKU_ave.csv'), index_col='sku_name')
        df_mrt_ave = pd.read_csv(os.path.join(ave_path, 'MRT_ave.csv'), index_col='MRT')
        df_dist_ave = pd.read_csv(os.path.join(ave_path, 'DIST_ave.csv'), index_col='é„‰é®å¸‚å€')

        n_data = df.shape[0] - 1
        temp = os.path.join(path, 'output\\temp')
        if not os.path.exists(temp):
            os.makedirs(temp)
        df = fn_gen_house_data(os.path.join(temp, file.name), 'test', df_validate=df)

        df['MRT_ave'] = df['MRT'].apply(lambda x: df_mrt_ave.loc[x, 'æ¯åªå–®åƒ¹(è¬)'])
        df['SKU_ave'] = df['sku_name'].apply(lambda x: df_sku_ave.loc[x, 'æ¯åªå–®åƒ¹(è¬)'])
        df['DIST_ave'] = df['é„‰é®å¸‚å€'].apply(lambda x: df_dist_ave.loc[x, 'æ¯åªå–®åƒ¹(è¬)'])

        if df.shape[0] and n_data:

            df = fn_cln_house_data(df.copy())

            df = df[df['å»ºç‰©å‹æ…‹'] == build_typ] if build_typ != 'ä¸é™' else df
            for i in df['ä¸»è¦å»ºæ'].tolist():
                if i not in df['ä¸»è¦å»ºæ'].unique():
                    print(i)

            X, df_cat = fn_gen_training_data(df.copy(), path, is_inference=True, df_F=df_F)
            df['æ¨¡å‹é ä¼°(è¬/åª)'] = model.predict(X)

            if is_rf:
                trees, conf = fn_gen_model_confidence(model, X)
                df['ä¿¡å¿ƒæŒ‡æ¨™'] = conf

            df['æ¨¡å‹é ä¼°(è¬/åª)'] = df['æ¨¡å‹é ä¼°(è¬/åª)'].apply(lambda x: round(x, 2))
            df['å·®(è¬/åª)'] = df['æ¨¡å‹é ä¼°(è¬/åª)'] - df['æ¯åªå–®åƒ¹(è¬)']
            df['èª¤å·®(è¬/åª)'] = df['å·®(è¬/åª)'].apply(lambda x: round(x, 2))
            df = df[df['ç§»è½‰å±¤æ¬¡'] > 1]
            df.sort_values(by=['èª¤å·®(è¬/åª)'], inplace=True, ignore_index=True)
            n_test = df.shape[0]
            st.write(f'æ­¤æª”å…±æœ‰{n_data}ç­† è³‡æ–™, ç¶“ç¯©é¸å¾Œæœ‰ {n_test}ç­† å¯é€²è¡Œæ¨¡å‹é ä¼°')

            show_cols = ['ä¿¡å¿ƒæŒ‡æ¨™'] if is_rf else []
            show_cols += ['èª¤å·®(è¬/åª)', 'æ¯åªå–®åƒ¹(è¬)', 'æ¨¡å‹é ä¼°(è¬/åª)', 'åœ°å€', 'ç§»è½‰å±¤æ¬¡', 'MRT']
            df_show = df[show_cols]

            # st.dataframe(df_show)

            if is_rf:
                config = {'scrollZoom': True,
                          'toImageButtonOptions': {'height': None, 'width': None}}

                st.write('')
                st.subheader(f'æ¨¡å‹å¯ä¿¡åº¦åˆ†æ')
                c1, c2 = st.columns(2)
                ths = c2.slider('ä¿¡å¿ƒé–€æª»', min_value=90, max_value=100, value=(96, 100))
                th_l, th_h = ths[0], ths[1]
                df_sel = df[df['ä¿¡å¿ƒæŒ‡æ¨™'].apply(lambda x: th_h >= x >= th_l)]

                colors = ['ç„¡', f'ä¾è¡Œæ”¿å€({len(df["é„‰é®å¸‚å€"].unique())})', 'ä¾æ·é‹è·é›¢', 'ä¾é€šå‹¤æ™‚é–“']
                color_by = c1.selectbox('è‘—è‰²æ¢ä»¶:', colors)

                margin = dict(t=50, l=20, r=0, b=0)
                fig = make_subplots()
                color_set, opacity = fn_set_color_by(color_by, df)
                hover_text = fn_get_hover_text(df)
                fig = fn_gen_plotly_scatter(fig, df['æ¯åªå–®åƒ¹(è¬)'], df['æ¨¡å‹é ä¼°(è¬/åª)'], margin=margin,
                                            color=color_set, text=hover_text, opacity=0.6)
                color_set, opacity = fn_set_color_by(color_by, df_sel)
                hover_text = fn_get_hover_text(df_sel)
                title = f'æ¨¡å‹: ml_model{model_name.split("ml_model")[-1]} çš„ å¯ä¿¡åº¦è©•ä¼° <br>' \
                        f'( æ­¤æ¨¡å‹é€²è¡Œ{df.shape[0]}ç­†é æ¸¬, ä¿¡å¿ƒæŒ‡æ¨™ä»‹æ–¼ {th_l} ~ {th_h} ' \
                        f'çš„ æœ‰{df_sel.shape[0]}ç­†, ç´„{int(100 * df_sel.shape[0] / df.shape[0])}% )'

                fig = fn_gen_plotly_scatter(fig, df_sel['æ¯åªå–®åƒ¹(è¬)'], df_sel['æ¨¡å‹é ä¼°(è¬/åª)'], margin=margin,
                                            color=color_set, text=hover_text, opacity=1,
                                            xlabel='å¯¦éš›å–®åƒ¹(è¬/åª)', ylabel='é ä¼°å–®åƒ¹(è¬/åª)', title=title)
                st.write('')
                st.plotly_chart(fig, config=config)

                fig = make_subplots(rows=2, cols=2, specs=[[{"rowspan": 1, "colspan": 2}, None], [{}, {}]],
                                    subplot_titles=('ä¿¡å¿ƒæŒ‡æ¨™v.s.çµ•å°èª¤å·®', 'ä¿¡å¿ƒåˆ†ä½ˆ', 'èª¤å·®(è¬/åª)åˆ†ä½ˆ'))

                fig = fn_gen_plotly_hist(fig, df['ä¿¡å¿ƒæŒ‡æ¨™'], 'ä¿¡å¿ƒæŒ‡æ¨™', row=2, col=1, margin=margin)
                fig = fn_gen_plotly_hist(fig, df['èª¤å·®(è¬/åª)'], 'èª¤å·®åˆ†å¸ƒ(è¬/åª)', row=2, col=2, margin=margin)

                color_set, opacity = fn_set_color_by(color_by, df)

                # hover_text = df['é„‰é®å¸‚å€']
                hover_text = fn_get_hover_text(df)

                fig = fn_gen_plotly_scatter(fig, df['ä¿¡å¿ƒæŒ‡æ¨™'], abs(df['èª¤å·®(è¬/åª)']), row=1, margin=margin,
                                            color=color_set, text=hover_text, opacity=0.6,
                                            xlabel='ä¿¡å¿ƒæŒ‡æ¨™(åˆ†)', ylabel='çµ•å°èª¤å·®(è¬/åª)')
                # fig.add_vline(x=96, row=2, line dash="dash", line_color-"red")

                if df_sel.shape[0] > 0:
                    err_max = max(abs(df_sel['èª¤å·®(è¬/åª)']))
                    fig.add_vrect(x0=-1 * err_max, row=2, col=2, x1=err_max, line_width=0, fillcolor="red", opacity=0.1)
                    fig.add_vrect(x0=th_l, row=2, col=1, x1=th_h, line_width=0, fillcolor="red", opacity=0.1)
                    fig.add_vrect(x0=th_l, row=1, col=1, x1=th_h, line_width=0, fillcolor="red", opacity=0.1)

                st.plotly_chart(fig, config=config)

            st.write('')
            AgGrid(df_show)

            del df
        else:
            st.write(f'æ­¤æª”å…±æœ‰ {n_data}ç­† è³‡æ–™, ç¶“ç¯©é¸å¾Œä¸å¯é€²è¡Œæ¨¡å‹é ä¼° !')


def fn_gen_training_data(df, path, is_inference=False, df_F=pd.DataFrame()):
    le = LabelEncoder()
    # df cat= df[['é„‰é®å¸‚å€,ä¸»è¦å»ºæ',è»Šä½é¡åˆ¥, 'MRT']]
    df.reset_index(drop=True, inplace=True)
    df_cat = df[['ä¸»è¦å»ºæ', 'è»Šä½é¡åˆ¥']]
    f_cat = []
    for col in df_cat.columns:
        cats = fn_get_categories(path, col)
        # df_f = pd.read_csv(os.path.join(path, f'output\\Feature_{col}.csv'))
        # cats = df_f[col].to_list()
        enc = OneHotEncoder(categories=[cats])
        one_hot = enc.fit_transform(df_cat[[col]]).toarray()
        df_oh = pd.DataFrame(one_hot)
        col_name = [col + '_' + str(cats[c]) for c in df_oh.columns]
        assert df.index[-1] == df_oh.index[
            -1], f'index NOT match !!! {df.shape, df_oh.shape} {df.index[-1], df_oh.index[-1]}'
        df[col_name] = df_oh
        df.drop(columns=col, inplace=True)
        f_cat = f_cat + col_name

    df['é ‚æ¨“'] = df['ç§»è½‰å±¤æ¬¡'].astype(int) - df['ç¸½æ¨“å±¤æ•¸'].astype(int)
    df['é ‚æ¨“-1'] = df['é ‚æ¨“'].apply(lambda x: 1 if x == -1 else 0)
    df['é ‚æ¨“'] = df['é ‚æ¨“'].apply(lambda x: 1 if x == 0 else 0)
    df['å»ºç‰©å‹æ…‹'] = df['ç¸½æ¨“å±¤æ•¸'].apply(lambda x: 1 if int(x) >= 11 else 0)

    df['ä½¿ç”¨åˆ†å€_ä½'] = df['éƒ½å¸‚åœŸåœ°ä½¿ç”¨åˆ†å€'].apply(lambda x: 1 if 'ä½' in x else 0) if 'éƒ½å¸‚åœŸåœ°ä½¿ç”¨åˆ†å€' in df.columns else 1

    df = fn_get_sku_people_by_year(df.copy())
    df = fn_get_interest_rate(df.copy(), months=24)

    f_num = ['å±‹é½¡', 'äº¤æ˜“å¹´']
    f_num += ['å°åŒ—å¸‚', 'ç·¯åº¦', 'ç¶“åº¦']
    f_num += ['å»ºç‰©åªæ•¸', 'è»Šä½åªæ•¸', 'å¹¾æˆ¿', 'å¹¾å»³', 'å¹¾è¡›']
    f_num += ['ç¸½æ¨“å±¤æ•¸', 'é ‚æ¨“', 'ç§»è½‰å±¤æ¬¡']
    f_num += ['sku_dist', 'sku_total']
    f_num += ['MRT_DIST', 'MRT_Tput_UL', 'MRT_Tput_DL', 'MRT_Tput', 'MRT_Commute_Time_UL']
    f_num += ['åˆ©ç‡_13å€‹æœˆå‰', 'åˆ©ç‡_15å€‹æœˆå‰']
    f_num += ['é ‚æ¨“-1']
    f_num += ['ä½¿ç”¨åˆ†å€_ä½']

    f_num += ['MRT_ave', 'SKU_ave', 'DIST_ave']

    if is_inference:
        Features = df_F['Features'].to_list()
    else:
        f_num += ['MRT']
        Features = f_num + f_cat

    if is_inference:
        Feature_sel = Features
    else:
        Feature_sel = []
        for f in Features:
            if len(df[f].unique()) > 1:
                Feature_sel.append(f)

    X = df[Feature_sel]

    for c in X.columns:
        if X[c].isna().any() and is_inference:
            print(c, X[[c]].shape, X.shape)
            for i, v in enumerate(X[c].tolist()):
                print(c, i, v, df_cat.iloc[i, :].values)
            assert False, c + str(f' is {X[c].values} {len(X[c].tolist())}')

    return X, df_cat


def fn_gen_model_explain(X, model):
    X.rename(columns={col: dic_of_cn_2_en[col] if col in dic_of_cn_2_en.keys() else col for col in X.columns},
             inplace=True)
    prediction, bias, contributions = treeinterpreter.predict(model, X.values)
    p = round(prediction[0][0], 2)
    b = round(bias[0], 2)
    cts = list(contributions[0])
    cts = [round(x, 2) for x in cts]
    fig = waterfall(X.columns, cts, threshold=0.01, sorted_value=True,
                    Title=f'Contribution of each Feature({X.shape[1]} features)\npred({p})= bias({b})+contributions({round(p - b, 2)})',
                    rotation_value=90, formatting='{:,.2f}')
    st.write('')
    st.subheader('æ¨¡å‹è§£é‡‹')
    st.pyplot(fig)
    print(X.columns)


def fn_gen_plotly_hist(fig, data, title, row=1, col=1, margin=None, bins=100, line_color='white', showlegend=False,
                       hovertext=None, barmode='group', opacity=0.8):
    fig.add_trace(
        go.Histogram(x=data, name=title, showlegend=showlegend, nbinsx=bins, hovertext=hovertext,
                     marker=dict(
                         opacity=opacity,
                         line=dict(
                             color=line_color, width=0.4
                         ),
                     )),
        row=row,
        col=col,
    )

    fig.update_layout(margin=margin,
                      barmode=barmode)

    return fig


def fn_gen_plotly_bar(df_top, x_data_col, y_data_col, text_col, v_or_h, margin,
                      color_col=None, text_fmt=None, title=None, ccs='agsunset'):
    fig = px.bar(df_top, x=x_data_col, y=y_data_col,
                 orientation=v_or_h, title=title,
                 text=text_col, color=color_col,
                 color_continuous_scale=ccs)

    fig.update_traces(texttemplate=text_fmt)
    fig.update_layout(margin=margin)

    return fig


def fn_gen_plotly_map(df, title, hover_name, hover_data, map_style,
                      color=None, zoom=10, height=400, text=None, margin=None):
    margin = {"r": 0, "t": 40, "l": 0, "b": 0} if margin is None else margin

    lat, lon = 'na', 'na'

    for y in ['ç·¯åº¦', 'lat']:
        if y in df.columns:
            lat = y
            break

    for x in ['ç¶“åº¦', 'log', 'lon']:
        if x in df.columns:
            lon = x
            break

    assert lat != 'na' and lon != 'na', f'This df have no coor col: {df.columns}'

    fig = px.scatter_mapbox(df,
                            lat=lat, lon=lon, title=title,
                            hover_name=hover_name, hover_data=hover_data,
                            color_discrete_sequence=["fuchsia"],
                            zoom=zoom, height=height, color=color,
                            text=text)

    fig.update_layout(mapbox_style=map_style, margin=margin)
    # map style - "open-street-map", "white-bg", "carto-positron", "stamen-terrain"
    return fig


def fn_gen_plotly_scatter(fig, x_data, y_data, row=1, col=1, margin=None, color=None, text=None, opacity=0.3,
                          xlabel=None, ylabel=None, title=None):
    fig.add_trace(go.Scatter(x=x_data, y=y_data, mode='markers', showlegend=False,
                             marker=dict(
                                 opacity=opacity,
                                 line={'color': 'White', 'width': 0.4},
                                 color=color,
                                 colorscale='Bluered')  # "Viridis")
                             ), row=row, col=col)

    if margin is not None:
        fig.update_layout(margin=margin)

    fig.update_layout(
        title={
            'text': title,
            'y': 0.95,
            'x': 0.5,
            'xanchor': 'center',
            'yanchor': 'top'
        },
        xaxis_title=xlabel,
        yaxis_title=ylabel,
        font=dict(size=13)
    )

    return fig


def fn_gen_df_color(val):
    color = 'greenyellow' if val else 'lightgray'

    return f'background-color: fcolor]'


def fn_gen_analysis_mrt(df, color_by, margin=None, bc_name=None):
    if bc_name is None:
        bc_name = ['åº·å¯¶æ—¥å‡ºå°è±¡']
    margin = {'l': 0, 'r': 50, 't': 30, 'b': 20} if margin is None else margin
    mrts = len(df['MRT'].unique())

    fig_sct = make_subplots(rows=3, cols=2,
                            specs=[[{"colspan": 2, "rowspan": 2}, None], [{}, {}], [{}, {}]],
                            subplot_titles=(f'{mrts}å€‹ é„°è¿‘æ·é‹ç«™ V.S. æ¯åªå–®åƒ¹(è¬)',))
    # df_sort = df.sort_values(by='æ¯åªå–®åƒ¹(è¬),ascending=True)
    df_sort = df.sort_values(by='MRT_ave', ascending=False)
    df_hl = df_sort[df_sort['å»ºæ¡ˆåç¨±'].apply(lambda x: x in bc_name)]

    hover_text = fn_get_hover_text(df_sort)

    color_set, opacity = fn_set_color_by(color_by, df_sort)

    fig_sct = fn_gen_plotly_scatter(fig_sct, df_sort['MRT'], df_sort['æ¯åªå–®åƒ¹(è¬)'],
                                    margin=margin, color=color_set, text=hover_text)

    hover_txt1 = fn_get_hover_text(df_hl)

    fig_sct = fn_gen_plotly_scatter(fig_sct, df_hl['MRT'], df_hl['æ¯åªå–®åƒ¹(è¬)'],
                                    margin=margin, color='red', text=hover_txt1, opacity=1)

    sub_titles = ['é„°è¿‘æ·é‹é€šå‹¤æ™‚é–“(åˆ†)', 'é„°è¿‘æ·é‹è·é›¢(å…¬å°º)', 'ä¸Šç­æ™‚é–“é€²ç«™äººæ•¸', 'ä¸Šç­æ™‚é–“å‡ºç«™äººæ•¸']

    fig_sct_1 = make_subplots(rows=2, cols=2,
                              specs=[[{}, {}], [{}, {}]],
                              subplot_titles=('é„°è¿‘æ·é‹é€šå‹¤æ™‚é–“(åˆ†) v.s æ¯åªå–®åƒ¹(è¬)',
                                              'é„°è¿‘æ·é‹è·é›¢(å…¬å°º) v.s æ¯åªå–®åƒ¹(è¬)',
                                              'ä¸Šç­æ™‚é–“é€²ç«™äººæ•¸ v.s æ¯åªå–®åƒ¹(è¬)',
                                              'ä¸Šç­æ™‚é–“å‡ºç«™äººæ•¸ v.s æ¯åªå–®åƒ¹(è¬)'))

    # hover_text = fn_get_hover_text(df_sort)

    y_data = df_sort['æ¯åªå–®åƒ¹(è¬)']
    y_hl = df_hl['æ¯åªå–®åƒ¹(è¬)']
    fig_sct_1 = fn_gen_plotly_scatter(fig_sct_1, df_sort['MRT_Commute_Time_UL'], y_data, row=1, col=1,
                                      margin=margin,
                                      color=color_set, text=hover_text)

    fig_sct_1 = fn_gen_plotly_scatter(fig_sct_1, df_hl['MRT_Commute_Time_UL'], y_hl, row=1, col=1,
                                      margin=margin,
                                      color='red', text=hover_txt1, opacity=1)

    fig_sct_1 = fn_gen_plotly_scatter(fig_sct_1, df_sort['MRT_DIST'], y_data, row=1, col=2, margin=margin,
                                      color=color_set, text=hover_text)

    fig_sct_1 = fn_gen_plotly_scatter(fig_sct_1, df_hl['MRT_DIST'], y_hl, row=1, col=2, margin=margin,
                                      color='red', text=hover_txt1, opacity=1)

    fig_sct_1 = fn_gen_plotly_scatter(fig_sct_1, df_sort['MRT_Tput_UL'], y_data, row=2, col=1, margin=margin,
                                      color=color_set, text=hover_text)

    fig_sct_1 = fn_gen_plotly_scatter(fig_sct_1, df_hl['MRT_Tput_UL'], y_hl, row=2, col=1, margin=margin,
                                      color='red', text=hover_txt1, opacity=1)

    fig_sct_1 = fn_gen_plotly_scatter(fig_sct_1, df_sort['MRT_Tput_DL'], y_data, row=2, col=2, margin=margin,
                                      color=color_set, text=hover_text)

    fig_sct_1 = fn_gen_plotly_scatter(fig_sct_1, df_hl['MRT_Tput_DL'], y_hl, row=2, col=2, margin=margin,
                                      color='red', text=hover_txt1, opacity=1)
    return fig_sct, fig_sct_1


def fn_gen_analysis_sku(df, color_by, margin=None, bc_name=None):
    if bc_name is None:
        bc_name = ['åº·å¯¶æ—¥å‡ºå°è±¡']
    SKUs = len(df['sku_name'].unique())
    margin = {'l': 0, 'r': 50, 't': 30, 'b': 20} if margin is None else margin

    df_sort = df.sort_values(by='SKU_ave', ascending=False)

    df_sort['sku_name'] = df_sort['sku_name'].apply(
        lambda x: x.replace('é«˜ä¸­', '').replace('ä¸­å­¸', '').replace('å¯¦é©—', '').replace('åœ‹ç«‹', ''))

    df_hl = df_sort[df_sort['å»ºæ¡ˆåç¨±'].apply(lambda x: x in bc_name)]
    color_set, opacity = fn_set_color_by(color_by, df_sort)

    y_data = df_sort['æ¯åªå–®åƒ¹(è¬)']

    hover_text = df_sort['sku_name'] + ', ' + \
                 df_sort['é„‰é®å¸‚å€'] + ', ' + \
                 df_sort['å»ºæ¡ˆåç¨±'].astype(str) + ', ' + \
                 df_sort['äº¤æ˜“å¹´'].astype(str) + 'å¹´, ' + \
                 df_sort['sku_dist'].astype(int).astype(str) + 'å…¬å°º, ' + \
                 df_sort['sku_109_total'].astype(int).astype(str) + 'äºº'

    fig_sku_1 = make_subplots(rows=3, cols=2,
                              specs=[[{"rowspan": 2, "colspan": 2}, None], [{}, {}], [{}, {}]],
                              subplot_titles=(f'{SKUs}å€‹é„°è¿‘å°å­¸ v.s.æ¯åªå–®åƒ¹(è¬)',))
    fig_sku_1 = fn_gen_plotly_scatter(fig_sku_1, df_sort['sku_name'], y_data, row=1, col=1, margin=margin,
                                      color=color_set, text=hover_text)

    hover_txt1 = df_hl['sku_name'] + ', ' + \
                 df_hl['é„‰é®å¸‚å€'] + ', ' + \
                 df_hl['å»ºæ¡ˆåç¨±'].astype(str) + ', ' + \
                 df_hl['äº¤æ˜“å¹´'].astype(str) + 'å¹´, ' + \
                 df_hl['sku_dist'].astype(int).astype(str) + 'å…¬å°º, ' + \
                 df_hl['sku_109_total'].astype(int).astype(str) + 'äºº'

    fig_sku_1 = fn_gen_plotly_scatter(fig_sku_1, df_hl['sku_name'], df_hl['æ¯åªå–®åƒ¹(è¬)'], row=1, col=1, margin=margin,
                                      color='red', text=hover_txt1, opacity=1)

    fig_sku_2 = make_subplots(rows=2, cols=2,
                              specs=[[{}, {}], [{}, {}]],
                              subplot_titles=('é„°è¿‘å°å­¸è·é›¢(å…¬å°º) v.s.åªå–®åƒ¹(è¬)',
                                              'é„°è¿‘å°å­¸äººæ•¸(äºº) v.s. æ¯åªå–®åƒ¹(è¬)'))

    fig_sku_2 = fn_gen_plotly_scatter(fig_sku_2, df_sort['sku_dist'], y_data, row=1, col=1, margin=margin,
                                      color=color_set, text=hover_text)

    fig_sku_2 = fn_gen_plotly_scatter(fig_sku_2, df_hl['sku_dist'], df_hl['æ¯åªå–®åƒ¹(è¬)'], row=1, col=1, margin=margin,
                                      color='red', text=hover_txt1, opacity=1)

    fig_sku_2 = fn_gen_plotly_scatter(fig_sku_2, df_sort['sku_109_total'], y_data, row=1, col=2,
                                      margin=margin, color=color_set, text=hover_text)

    fig_sku_2 = fn_gen_plotly_scatter(fig_sku_2, df_hl['sku_109_total'], df_hl['æ¯åªå–®åƒ¹(è¬)'], row=1, col=2, margin=margin,
                                      color='red', text=hover_txt1, opacity=1)

    return fig_sku_1, fig_sku_2


def fn_gen_analysis_building(df, target, color_by, margin=None, bc_name=None):
    if bc_name is None:
        bc_name = ['åº·å¯¶æ—¥å‡ºå°è±¡']
    margin = {'l': 0, 'r': 50, 't': 30, 'b': 20} if margin is None else margin
    y_data = df[target]

    color_set, opacity = fn_set_color_by(color_by, df)

    hover_text = df['é„‰é®å¸‚å€'] + ', ' + \
                 df['å»ºæ¡ˆåç¨±'].astype(str) + ', ' + \
                 df['äº¤æ˜“å¹´'].astype(str) + 'å¹´, ' + \
                 df['å»ºç‰©åªæ•¸'].astype(int).astype(str) + 'åª, ' + \
                 df['ç¸½æ¨“å±¤æ•¸'].astype(int).astype(str) + 'æ¨“'

    df_hl = df[df['å»ºæ¡ˆåç¨±'].apply(lambda x: x in bc_name)]  # <--

    fig_sct_3 = make_subplots(rows=2, cols=2,
                              subplot_titles=(f'äº¤æ˜“å¹´ v.s. {target}', f'å»ºç‰©åªæ•¸ v.s. {target}',
                                              f'ç§»è½‰å±¤æ¬¡ v.s {target}', f'ç¸½æ¨“å±¤æ•¸ v.s. {target}'))

    fig_sct_3 = fn_gen_plotly_scatter(fig_sct_3, df['äº¤æ˜“å¹´'], y_data, row=1, col=1, margin=margin, color=color_set,
                                      text=hover_text, opacity=opacity)

    hover_txt1 = df_hl['é„‰é®å¸‚å€'] + ',' + \
                 df_hl['å»ºæ¡ˆåç¨±'].astype(str) + ',' + \
                 df_hl['äº¤æ˜“å¹´'].astype(str) + 'å¹´,' + \
                 df_hl['å»ºç‰©åªæ•¸'].astype(int).astype(str) + 'åª,' + \
                 df_hl['ç¸½æ¨“å±¤æ•¸'].astype(int).astype(str) + 'æ¨“'

    fig_sct_3 = fn_gen_plotly_scatter(fig_sct_3, df_hl['äº¤æ˜“å¹´'], df_hl[target], row=1, col=1, margin=margin, color='red',
                                      text=hover_txt1, opacity=1)

    fig_sct_3 = fn_gen_plotly_scatter(fig_sct_3, df['å»ºç‰©åªæ•¸'], y_data, row=1, col=2, margin=margin, color=color_set,
                                      text=hover_text, opacity=opacity)

    fig_sct_3 = fn_gen_plotly_scatter(fig_sct_3, df_hl['å»ºç‰©åªæ•¸'], df_hl[target], row=1, col=2, margin=margin,
                                      color='red',
                                      text=hover_txt1, opacity=1)

    fig_sct_3 = fn_gen_plotly_scatter(fig_sct_3, df['ç§»è½‰å±¤æ¬¡'], y_data, row=2, col=1, margin=margin, color=color_set,
                                      text=hover_text, opacity=opacity)

    fig_sct_3 = fn_gen_plotly_scatter(fig_sct_3, df_hl['ç§»è½‰å±¤æ¬¡'], df_hl[target], row=2, col=1, margin=margin,
                                      color='red',
                                      text=hover_txt1, opacity=1)

    fig_sct_3 = fn_gen_plotly_scatter(fig_sct_3, df['ç¸½æ¨“å±¤æ•¸'], y_data, row=2, col=2, margin=margin, color=color_set,
                                      text=hover_text, opacity=opacity)

    fig_sct_3 = fn_gen_plotly_scatter(fig_sct_3, df_hl['ç¸½æ¨“å±¤æ•¸'], df_hl[target], row=2, col=2, margin=margin, color='red',
                                      text=hover_txt1, opacity=1)
    return fig_sct_3


def fn_gen_analysis_statistic(df):
    fig_bar = make_subplots(rows=2, cols=2, subplot_titles=('äº¤æ˜“å¹´', 'äº¤æ˜“æœˆ', 'æ¯åªå–®åƒ¹(è¬)', 'ç¸½åƒ¹(è¬)'))
    margin = {'l': 0, 'r': 50, 't': 30, 'b': 20}

    fig_bar = fn_gen_plotly_hist(fig_bar, df['äº¤æ˜“å¹´'], 'äº¤æ˜“å¹´', row=1, col=1, bins=30, margin=margin)
    fig_bar = fn_gen_plotly_hist(fig_bar, df['äº¤æ˜“æœˆ'], 'äº¤æ˜“æœˆ', row=1, col=2, bins=50, margin=margin)
    fig_bar = fn_gen_plotly_hist(fig_bar, df['æ¯åªå–®åƒ¹(è¬)'], 'å–®åƒ¹(è¬åª)', row=2, col=1, bins=50, margin=margin)
    fig_bar = fn_gen_plotly_hist(fig_bar, df['ç¸½åƒ¹(è¬)'], 'ç¸½åƒ¹(è¬)', row=2, col=2, bins=50, margin=margin)

    fig_bar_2 = make_subplots(rows=2, cols=2, subplot_titles=('å»ºç‰©åªæ•¸', 'ç¸½æ¨“å±¤æ•¸', 'è»Šä½é¡åˆ¥', 'è»Šä½å–®åƒ¹(è¬)'))
    fig_bar_2 = fn_gen_plotly_hist(fig_bar_2, df['å»ºç‰©åªæ•¸'], 'å»ºç‰©åªæ•¸', row=1, col=1, bins=50, margin=margin)
    fig_bar_2 = fn_gen_plotly_hist(fig_bar_2, df['ç¸½æ¨“å±¤æ•¸'], 'ç¸½æ¨“å±¤æ•¸', row=1, col=2, bins=50, margin=margin)
    fig_bar_2 = fn_gen_plotly_hist(fig_bar_2, df['è»Šä½é¡åˆ¥'], 'è»Šä½é¡åˆ¥', row=2, col=1, bins=50, margin=margin)
    fig_bar_2 = fn_gen_plotly_hist(fig_bar_2, df['è»Šä½å–®åƒ¹(è¬)'], 'è»Šä½å–®åƒ¹(è¬)', row=2, col=2, bins=50, margin=margin)

    df_pk_1 = df[df['è»Šä½é¡åˆ¥'] == 'å¡é“å¹³é¢']
    df_pk_2 = df[df['è»Šä½é¡åˆ¥'] == 'å¡é“æ©Ÿæ¢°']
    fig_bar_3 = make_subplots(rows=2, cols=2,
                              subplot_titles=('å¡é“å¹³é¢ çš„ åƒ¹æ ¼åˆ†ä½ˆ', 'å¡é“å¹³é¢ çš„ åªæ•¸åˆ†ä½ˆ', 'å¡é“æ©Ÿæ¢° çš„ åƒ¹æ ¼åˆ†ä½ˆ', 'å¡é“æ©Ÿæ¢° çš„ åªæ•¸åˆ†ä½ˆ'))
    fig_bar_3 = fn_gen_plotly_hist(fig_bar_3, df_pk_1['è»Šä½å–®åƒ¹(è¬)'], 'è»Šä½å–®åƒ¹(è¬)', row=1, col=1, bins=50, margin=margin)
    fig_bar_3 = fn_gen_plotly_hist(fig_bar_3, df_pk_1['è»Šä½åªæ•¸'], 'è»Šä½åªæ•¸', row=1, col=2, bins=50, margin=margin)
    fig_bar_3 = fn_gen_plotly_hist(fig_bar_3, df_pk_2['è»Šä½å–®åƒ¹(è¬)'], 'è»Šä½å–®åƒ¹(è¬)', row=2, col=1, bins=50, margin=margin)
    fig_bar_3 = fn_gen_plotly_hist(fig_bar_3, df_pk_2['è»Šä½åªæ•¸'], 'è»Šä½åªæ•¸', row=2, col=2, bins=50, margin=margin)

    dists = len(df['é„‰é®å¸‚å€'].unique())
    df_typ = df[df['éƒ½å¸‚åœŸåœ°ä½¿ç”¨åˆ†å€'].apply(lambda x: x == 'ä½' or x == 'å•†')]
    fig_bar_4 = make_subplots(rows=2, cols=2, subplot_titles=(f'åœŸåœ°ä½¿ç”¨åˆ†å€', f'è¡Œæ”¿å€({dists}å€‹)', '', ''))
    fig_bar_4 = fn_gen_plotly_hist(fig_bar_4, df_typ['éƒ½å¸‚åœŸåœ°ä½¿ç”¨åˆ†å€'], 'åœŸåœ°ä½¿ç”¨åˆ†å€', row=1, col=1, bins=50, margin=margin)
    fig_bar_4 = fn_gen_plotly_hist(fig_bar_4, df['é„‰é®å¸‚å€'], 'è¡Œæ”¿å€', row=1, col=2, bins=50, margin=margin)

    return fig_bar, fig_bar_2, fig_bar_3, fig_bar_4


def fn_gen_analysis(df, latest_records, build_case):
    config = {'scrollZoom': True,
              'toImageButtonOptions': {'height': None, 'width': None}}

    with st.expander(f'ğŸ‘“ æª¢è¦– æ¯åªå–®åƒ¹ çš„ åˆ†ä½ˆç‹€æ³'):
        fig_3d = px.scatter_3d(df, x='ç¶“åº¦', y='ç·¯åº¦', z='æ¯åªå–®åƒ¹(è¬)', color='æ¯åªå–®åƒ¹(è¬)',
                               hover_data=['é„‰é®å¸‚å€', 'å»ºæ¡ˆåç¨±', 'äº¤æ˜“å¹´', 'MRT', 'sku_name'],
                               opacity=0.8)
        fig_3d.update_layout(title='æ¯åªå–®åƒ¹ çš„ åˆ†ä½ˆç‹€æ³', autosize=True,
                             width=700, height=500,
                             margin={'l': 0, 'r': 0, 't': 30, 'b': 20})
        st.plotly_chart(fig_3d)

        fig_c = go.Figure(data=go.Contour(x=df['ç¶“åº¦'], y=df['ç·¯åº¦'], z=df['coor_ave'], line_smoothing=1.2))
        fig_c.update_layout(title='æ¯åªå–®åƒ¹çš„åˆ†ä½ˆç‹€æ³', autosize=True,
                            margin={'l': 50, 'r': 20, 't': 30, 'b': 20})
        st.plotly_chart(fig_c)

    with st.expander(f'ğŸ‘“ æª¢è¦– ç‰©ä»¶ç‰¹å¾µçš„åˆ†å¸ƒç‹€æ³'):
        fig_bar, fig_bar_2, fig_bar_3, fig_bar_4 = fn_gen_analysis_statistic(df)
        st.plotly_chart(fig_bar, config=config)
        st.plotly_chart(fig_bar_2, config=config)
        st.plotly_chart(fig_bar_3, config=config)
        st.plotly_chart(fig_bar_4, config=config)

    with st.expander(f'ğŸ‘“ æª¢è¦– æ¯åªå–®åƒ¹ èˆ‡ "å„é …"æŒ‡æ¨™ çš„é—œä¿‚'):
        # fig= plot_correlation(df,'æ¯åªå–®åƒ¹(è¬))
        # st.write(fig)
        title = 'æ¯åªå–®åƒ¹ èˆ‡ "å„é …æŒ‡æ¨™" çš„é—œä¿‚'
        target = [dict(label='æ¯åªå–®åƒ¹', values=df['æ¯åªå–®åƒ¹(è¬)'])]

        dimensions = [
            dict(label='é€šå‹¤æ™‚é–“', values=df['MRT_Commute_Time_UL']),
            dict(label='æ·é‹è·é›¢', values=df['MRT_DIST']),
            dict(label='é€²ç«™äººæ•¸', values=df['MRT_Tput_UL']),
            dict(label='å‡ºç«™äººæ•¸', values=df['MRT_Tput_DL']),

            dict(label='å°å­¸è·é›¢', values=df['sku_dist']),
            dict(label='å°å­¸äººæ•¸', values=df['sku_109_total']),
            dict(label='äº¤æ˜“æ¨“å±¤', values=df['ç§»è½‰å±¤æ¬¡']),
            dict(label='ç¸½æ¨“å±¤æ•¸', values=df['ç¸½æ¨“å±¤æ•¸']),

            dict(label='äº¤æ˜“å¹´åº¦', values=df['äº¤æ˜“å¹´']),
            dict(label='å»ºç‰©åªæ•¸', values=df['å»ºç‰©åªæ•¸']),
            dict(label='ç¶“åº¦', values=df['ç¶“åº¦']),
            dict(label='ç·¯åº¦', values=df['ç·¯åº¦']),

            dict(label='åº§æ¨™å¹³å‡', values=df['coor_ave']),
            dict(label='å­¸å€å¹³å‡', values=df['SKU_ave']),
            dict(label='æ·é‹å¹³å‡', values=df['MRT_ave']),
            dict(label='è¡Œæ”¿å€å¹³å‡', values=df['DIST_ave']),
        ]

        figs = 4
        d1 = dimensions[:figs]
        d2 = dimensions[figs: 2 * figs]
        d3 = dimensions[2 * figs: 3 * figs]
        d4 = dimensions[3 * figs: 4 * figs]

        for d in [d1, d2, d3, d4]:
            fig = go.Figure(data=go.Splom(
                dimensions=d + target,
                diagonal=dict(visible=False),
                showupperhalf=False,
                marker=dict(color=df['æ¯åªå–®åƒ¹(è¬)'],
                            size=6,
                            colorscale='Bluered',
                            line=dict(width=0.5,
                                      color='rgb(230,230,230)'))))

            fig.update_layout(title=title,
                              dragmode='select',
                              width=800,
                              height=800,
                              hovermode='closest')

            st.plotly_chart(fig, config=config)

    with st.expander(f'ğŸ‘“ æª¢è¦– æ¯åªå–®åƒ¹ èˆ‡ "æ·é‹"æŒ‡æ¨™ çš„é—œä¿‚'):
        color_by = st.radio('è‘—è‰²æ¢ä»¶:', options=['ç„¡', 'ä¾æ·é‹è·é›¢', 'ä¾é€šå‹¤æ™‚é–“', f'ä¾æœ€æ–°ç™»éŒ„({latest_records})'], index=0)
        fn_set_radio_2_hor()
        fig_sct, fig_sct_1 = fn_gen_analysis_mrt(df, color_by, bc_name=[build_case])
        st.plotly_chart(fig_sct, config=config)
        st.plotly_chart(fig_sct_1, config=config)

    with st.expander(f'ğŸ‘“ æª¢è¦– æ¯åªå–®åƒ¹ èˆ‡ "å°å­¸"æŒ‡æ¨™ çš„é—œä¿‚'):
        color_by = st.radio('è‘—è‰²æ¢ä»¶:', options=['ç„¡', 'ä¾å°å­¸è·é›¢', 'ä¾å°å­¸äººæ•¸', f'ä¾æœ€æ–°ç™»éŒ„({latest_records})'], index=0)
        fn_set_radio_2_hor()
        fig_sku_1, fig_sku_2 = fn_gen_analysis_sku(df, color_by, bc_name=[build_case])
        st.plotly_chart(fig_sku_1, config=config)
        st.plotly_chart(fig_sku_2, config=config)

    with st.expander(f'ğŸ‘“ æª¢è¦– æ¯åªå–®åƒ¹ èˆ‡ "å»ºç‰©"æŒ‡æ¨™ çš„é—œä¿‚'):
        color_by = st.radio('è‘—è‰²æ¢ä»¶:', options=['ç„¡', 'ä¾äº¤æ˜“å¹´', 'ä¾ç¸½æ¨“å±¤æ•¸', 'ä¾å»ºç‰©åªæ•¸', f'ä¾æœ€æ–°ç™»({latest_records})'], index=0)
        fn_set_radio_2_hor()
        fig_sct_3 = fn_gen_analysis_building(df, 'æ¯åªå–®åƒ¹(è¬)', color_by, bc_name=[build_case])
        st.plotly_chart(fig_sct_3, config=config)

    with st.expander(f'ğŸ‘“ æª¢è¦– ç‰©ä»¶ç¸½åƒ¹ èˆ‡ "å»ºç‰©"æŒ‡æ¨™ çš„é—œä¿‚'):
        color_by = st.radio('è‘—è‰²æ¢ä»¶:', options=['ç„¡', 'ä¾äº¤æ˜“å¹´', 'ä¾ç¸½æ¨“å±¤æ•¸', 'ä¾å»ºç‰©åªæ•¸', f'ä¾æœ€æ–°ç™»éŒ„({latest_records})'], index=0,
                            key=1)
        fn_set_radio_2_hor()
        fig_sct_3 = fn_gen_analysis_building(df, 'ç¸½åƒ¹(è¬)', color_by, bc_name=[build_case])
        st.plotly_chart(fig_sct_3, config=config)


def fn_gen_bc_deals(build_case, dic_df_show):
    if len(dic_df_show.keys()):
        deals = np.count_nonzero(dic_df_show['æ¯åªå–®åƒ¹(è¬)'])
        st.write('')
        st.subheader(f'ğŸ¡ å»ºæ¡ˆ: {build_case}'
                     f'ğŸ“ ç™»éŒ„: {deals} ç­†'
                     f'ğŸ’° ç¸½é‡‘é¡: {round((dic_df_show["ç¸½åƒ¹(è¬)"].values.sum()) / 10000, 2)} å„„')

        r = st.radio('æª¢è¦–é¸é …:', options=['ç¸½åƒ¹(è¬)', 'æ¯åªå–®åƒ¹(è¬)', 'å»ºç‰©åªæ•¸', 'è»Šä½åªæ•¸', 'ç¸½åƒ¹-è»Šä½(è¬)', 'è»Šä½ç¸½åƒ¹(è¬)', 'äº¤æ˜“æ—¥æœŸ'], index=0)
        fn_set_radio_2_hor()

        df_show = dic_df_show[r] if r in dic_df_show.keys() else None
        assert df_show is not None, f'{r} not in dic_df_show {dic_df_show.keys()}'
        fmt = "{:.2f}" if r in ['æ¯åªå–®åƒ¹(è¬)', 'å»ºç‰©åªæ•¸', 'è»Šä½åªæ•¸'] else None
        df_show = df_show.astype(int) if r == 'äº¤æ˜“æ—¥æœŸ' else df_show
        df_show_fig = df_show.style.format(fmt).applymap(fn_gen_df_color).highlight_max(axis=1, color='pink')
        df_show_fig = df_show_fig.background_gradient(cmap='rainbow', low=0.8, high=0, axis=None)
        st.dataframe(df_show_fig, width=768, height=540)
        dic_values = defaultdict(list)
        for col in df_show.columns:
            for idx in df_show.index:
                v = df_show.loc[idx, col]
                a = dic_df_show['å»ºç‰©åªæ•¸'].loc[idx, col]
                if v > 0:
                    dic_values[a].append(v)

        fig = make_subplots(rows=1, cols=1,
                            subplot_titles=(
                                f'å»ºæ¡ˆ-{build_case}: {len(dic_values.keys())}ç¨®åªæ•¸ å…±{deals}ç­†äº¤æ˜“ çš„ "{r}" åˆ†å¸ƒ',))

        margin = {'l': 40}
        for k in dic_values.keys():
            fig = fn_gen_plotly_hist(fig, dic_values[k], f'{str(k)}åª{r}', bins=50, margin=margin,
                                     line_color='black', showlegend=True)
        st.plotly_chart(fig)


def fn_gen_model_confidence(loaded_model, X):
    preds = np.stack([t.predict(X.values) for t in loaded_model.estimators_])
    trees = preds.shape[0]
    stds = preds.std(0)
    preds_std = list(map(lambda x: round(x, 2), stds))
    conf = list(map(lambda x: round(100 - x, 2), preds_std))
    # preds_std = round(preds.std(0)[0],2)
    # conf = 100 - preds_std
    # print(X.shape, preds.shape, trees, stds.shape, len(preds_std), len(conf))

    return trees, conf


def fn_gen_web_eda(df):
    t_s = time.time()

    df_sel = df.copy()
    options = list(df_sel[['MRT']].sort_values(by='MRT')['MRT'].unique()) + ['ä¸é™']
    idx = options.index('Rç·š_é—œæ¸¡ç«™') if 'Rç·š_é—œæ¸¡ç«™' in options else 0
    mrt = st.sidebar.selectbox('æ·é‹ç«™', options=options, index=idx)
    df_sel = df_sel.reset_index(drop=True) if mrt == 'ä¸é™' else df_sel[df_sel['MRT'] == mrt].reset_index(drop=True)

    build_cases = ['ä¸é™'] + [b for b in df_sel['å»ºæ¡ˆåç¨±'].astype(str).unique()]
    build_cases.remove('nan') if 'nan' in build_cases else None
    build_case = st.sidebar.selectbox('å»ºæ¡ˆåç¨±', options=build_cases, index=len(build_cases) - 1)
    df_sel = df_sel[df_sel['å»ºæ¡ˆåç¨±'] == build_case].reset_index(drop=True) if build_case != 'ä¸é™' else df_sel

    floor = st.sidebar.selectbox('ç§»è½‰å±¤æ¬¡', (0, *df_sel['ç§»è½‰å±¤æ¬¡'].unique()))
    df_sel = df_sel[df_sel['ç§»è½‰å±¤æ¬¡'] == floor].reset_index(drop=True) if floor != 0 else df_sel

    From = str(df_sel['äº¤æ˜“å¹´æœˆæ—¥'].iloc[-1])
    From = From[0:-4] + 'å¹´' + From[-4].replace('0', '') + From[-3] + 'æœˆ'
    To = str(df_sel['äº¤æ˜“å¹´æœˆæ—¥'].iloc[0])
    To = To[0:-4] + 'å¹´' + To[-4].replace('0', '') + To[-3] + 'æœˆ'

    From_To = f'{From} è‡³ {To} æœ‰{len(df_sel)}ç­†äº¤æ˜“'
    ave = round(df_sel['æ¯åªå–®åƒ¹(è¬)'].mean(), 0)

    # df_bc = pd.DataFrame()
    dic_df_show = dict()
    if build_case != 'ä¸é™' and not build_case.endswith('å€'):
        floor_max = df_sel['ç¸½æ¨“å±¤æ•¸'].max()
        floor_list = [str(floor_max - i) + 'F' for i in range(floor_max)]

        if len(df_sel['æˆ¶åˆ¥'].unique()) == 1:
            df_sel['house_num'] = df_sel['åœŸåœ°ä½ç½®å»ºç‰©é–€ç‰Œ'].apply(fn_addr_2_house_num)
        else:
            df_sel['house_num'] = df_sel['æˆ¶åˆ¥'].apply(lambda x: x.split('-')[0] if '-' in x else x)

        house_nums = sorted(df_sel['house_num'].unique())

        df_bc = pd.DataFrame(index=floor_list, columns=house_nums)
        df_bc_t = df_bc.copy()
        df_bc_car = df_bc.copy()
        df_bc_s = df_bc.copy()
        df_bc_ps = df_bc.copy()
        df_bc_d = df_bc.copy()

        df_sel_sort = df_sel.sort_values(by='äº¤æ˜“å¹´æœˆæ—¥', ascending=True)
        # print(f'{df_sel[["ç§»è½‰å±¤æ¬¡", "å»ºç‰©åªæ•¸"]]}')
        for idx in df_sel_sort.index:
            flr = str(df_sel_sort.loc[idx, 'ç§»è½‰å±¤æ¬¡']) + 'F'
            num = df_sel_sort.loc[idx, 'house_num']
            val, total, car, size, p_size, date = df_sel_sort.loc[
                idx, ['æ¯åªå–®åƒ¹(è¬)', 'ç¸½åƒ¹(è¬)', 'è»Šä½ç¸½åƒ¹(è¬)', 'å»ºç‰©åªæ•¸', 'è»Šä½åªæ•¸', 'äº¤æ˜“å¹´æœˆæ—¥']]

            df_bc.at[flr, num] = round(val, 2)
            df_bc_t.at[flr, num] = total
            df_bc_car.at[flr, num] = car
            df_bc_s.at[flr, num] = size
            df_bc_ps.at[flr, num] = p_size
            df_bc_d.at[flr, num] = date
            # print(f'{flr}, {p_size}, {size}')

        df_bc.fillna(round(0, 1), inplace=True)
        df_bc_t.fillna(round(0, 1), inplace=True)
        df_bc_car.fillna(round(0, 1), inplace=True)
        df_bc_s.fillna(round(0, 1), inplace=True)
        df_bc_ps.fillna(round(0, 1), inplace=True)
        df_bc_d.fillna(round(0, 1), inplace=True)
        if floor != 0:
            df_bc = df_bc[df_bc.index == str(floor) + 'F']
            df_bc_t = df_bc_t[df_bc_t.index == str(floor) + 'F']
            df_bc_car = df_bc_car[df_bc_car.index == str(floor) + 'F']
            df_bc_s = df_bc_s[df_bc_s.index == str(floor) + 'F']
            df_bc_ps = df_bc_ps[df_bc_ps.index == str(floor) + 'F']
            df_bc_d = df_bc_d[df_bc_d.index == str(floor) + 'F']

        dic_df_show['æ¯åªå–®åƒ¹(è¬)'] = df_bc[df_bc.sum(axis=1) > 0]
        dic_df_show['ç¸½åƒ¹(è¬)'] = df_bc_t[df_bc_t.sum(axis=1) > 0]
        dic_df_show['è»Šä½ç¸½åƒ¹(è¬)'] = df_bc_car[df_bc_car.sum(axis=1) > 0]
        dic_df_show['å»ºç‰©åªæ•¸'] = df_bc_s[df_bc_s.sum(axis=1) > 0]
        dic_df_show['è»Šä½åªæ•¸'] = df_bc_ps[df_bc_ps.sum(axis=1) > 0]
        # dic_df_show['å»ºç‰©-è»Šä½(åª)'] = dic_df_show['å»ºç‰©åªæ•¸'] - dic_df_show['è»Šä½åªæ•¸']
        dic_df_show['ç¸½åƒ¹-è»Šä½(è¬)'] = dic_df_show['ç¸½åƒ¹(è¬)'] - dic_df_show['è»Šä½ç¸½åƒ¹(è¬)']
        dic_df_show['äº¤æ˜“æ—¥æœŸ'] = df_bc_d[df_bc_d.sum(axis=1) > 0] / 100
        # print(f'{dic_df_show["å»ºç‰©åªæ•¸"] }')

    floors = list(df_sel['ç§»è½‰å±¤æ¬¡'].unique())
    floors.sort()
    prices = []
    deals = []
    for f in floors:
        price = int(df_sel[df_sel['ç§»è½‰å±¤æ¬¡'] == f]['æ¯åªå–®åƒ¹(è¬)'].mean())
        deal = len(df_sel[df_sel['ç§»è½‰å±¤æ¬¡'] == f])
        prices.append(price)
        deals.append(deal)

    floors = [str(f) + 'F' for f in floors]
    fig_bar2 = go.Figure(data=[
        go.Bar(name='å‡åƒ¹(è¬/åª)', x=floors, y=prices),
        go.Bar(name='æˆäº¤æˆ¶æ•¸', x=floors, y=deals)
    ],
        layout={'title': f'{mrt} ({From_To})'})

    fig_bar2.update_layout(barmode='group',  # One of 'group', 'overlay' or 'relative'
                           margin=dict(l=30, r=20, t=60, b=40),
                           paper_bgcolor="LightsteelBlue",
                           font=dict(size=16))

    df_sel.rename(columns={'log': 'lon'}, inplace=True)  # rename for st.map

    # df_sel['æ¯åªå–®åƒ¹(è¬)']=df_sel['æ¯åªå–®åƒ¹(è¬)'].astype(int)
    df_sel['MRT_DIST'] = df_sel['MRT_DIST'].astype(int)

    df_sel.rename(columns={'MRT': 'æ·é‹ç«™', 'MRT_DIST': 'æ·é‹ç«™è·é›¢(m)'}, inplace=True)

    cols = st.sidebar.multiselect('æ¬„ä½é¸æ“‡', df_sel.columns, default=['æ·é‹ç«™', 'å»ºæ¡ˆåç¨±', 'ç§»è½‰å±¤æ¬¡', 'å»ºç‰©åªæ•¸', 'è»Šä½åªæ•¸',
                                                                   'è»Šä½é¡åˆ¥', 'ç¸½åƒ¹(è¬)', 'æ¯åªå–®åƒ¹(è¬)', 'è»Šä½å–®åƒ¹(è¬)',
                                                                   'äº¤æ˜“å¹´æœˆæ—¥', 'åœ°å€'])

    df_cols = df_sel[cols]

    width = []
    for col in df_cols.columns:
        w = df_cols[col].apply(lambda x: len(str(x)))
        w = max((*w, len(col)))
        width.append(w)

    fig_tbl = go.Figure(data=[
        go.Table(columnwidth=width,
                 header=dict(values=list(df_cols.columns),
                             align='center',
                             font_size=14),
                 cells=dict(values=[df_cols[[col]] for col in df_cols.columns],
                            align='center',
                            font_size=14)
                 )])
    fig_tbl.update_layout(margin=dict(t=2, b=2, l=1, r=1))

    house_typ = 'é å”®å±‹' if len(df['å»ºç¯‰å®Œæˆå¹´æœˆ'].unique()) == 1 else 'ä¸­å¤å±‹'
    # city = df['åœŸåœ°ä½ç½®å»ºç‰©é–€ç‰Œ'].apply(lambda x:x.split('å¸‚')+'å¸‚')
    # city = city.unique()

    period = f"æ°‘åœ‹ {df['äº¤æ˜“å¹´'].min()}å¹´ ~ {df['äº¤æ˜“å¹´'].max()}å¹´"
    title = f'{period}: {df.shape[0]} ç­† {house_typ} å¯¦åƒ¹ç™»éŒ„è³‡æ–™'
    hover_name = 'äº¤æ˜“å¹´æœˆæ—¥'
    hover_data = ["MRT", "å»ºæ¡ˆåç¨±"]
    color = 'æ¯åªå–®åƒ¹(è¬)'
    map_style = "carto-positron"  # "open-street-map"
    fig_map_all = fn_gen_plotly_map(df, title, hover_name, hover_data, map_style, color=color)

    latest_rel = '0211'
    records = int(df.shape[0] - np.count_nonzero(df['Latest']))
    latest_records = f'ç‰ˆæœ¬:{latest_rel} æœ‰ {records}ç­†'
    city = list(df['city'].unique())
    cities = ''
    for c in city:
        cities = cities + c + ' '

    # rendering web view

    st.subheader(f'ğŸ™ï¸ {cities} {house_typ} å¯¦åƒ¹ç™»éŒ„åˆ†æ')
    st.plotly_chart(fig_map_all)

    st.write('')
    st.subheader(f'ğŸ“Š æ•¸æ“šåˆ†æ')
    fn_gen_analysis(df, latest_records, build_case)

    st.write('')
    st.subheader(f'ğŸš‡ æ·é‹ {mrt.split("_")[-1]} å‘¨é‚Š')
    st.subheader(From_To)
    st.subheader(f'å‡åƒ¹ {int(ave)} è¬/åª')
    st.write('è³‡æ–™ä¾†æº: [å†…æ”¿éƒ¨ä¸å‹•ç”¢äº¤æ˜“å¯¦åƒ¹æŸ¥è©¢æœå‹™ç¶²(æ¯æœˆ1ã€11ã€21 æ—¥ç™¼å¸ƒ)](https://plvr.land.moi.gov.tw/DownloadOpenData)')
    df_cols = df_cols.sort_values(by='ç§»è½‰å±¤æ¬¡', ascending=False) if 'ç§»è½‰å±¤æ¬¡' in df_cols.columns else df_cols
    AgGrid(df_cols)

    fn_gen_bc_deals(build_case, dic_df_show)

    st.write('')
    st.subheader('ğŸ—ºï¸ å»ºæ¡ˆä½ç½®')
    df_sel['æ¯åªå–®åƒ¹'] = df_sel['æ¯åªå–®åƒ¹(è¬)'].apply(lambda x: str(x) + 'è¬/åª')

    title = 'è¡—æ™¯åœ–'
    hover_name = 'å»ºæ¡ˆåç¨±'
    hover_data = ['äº¤æ˜“å¹´', 'ç¸½åƒ¹(è¬)', 'æ¯åªå–®åƒ¹(è¬)', 'è»Šä½å–®åƒ¹(è¬)',
                  'è»Šä½é¡åˆ¥', 'ç§»è½‰å±¤æ¬¡', 'æ·é‹ç«™', 'æ·é‹ç«™è·é›¢(m)', ]
    map_style = "open-street-map"
    fig_map = fn_gen_plotly_map(df_sel, title, hover_name, hover_data, map_style, zoom=14)

    st.plotly_chart(fig_map)
    st.subheader('ğŸ“ˆ æ¨“å±¤å‡åƒ¹ èˆ‡ æˆäº¤æˆ¶æ•¸')
    st.plotly_chart(fig_bar2)

    t_e = time.time()
    dur_t = round(t_e - t_s, 5)
    print(f'fn_gen_web_eda: {dur_t} ç§’')


def fn_gen_web_ml_train(df, path):
    ts = time.time()

    ml_model = os.path.join(path, 'output/model')

    # df =df[df['å»ºæ¡ˆåç¨±']!='åº·å¯¶æ—¥å‡ºå°è±¡']

    if not os.path.exists(ml_model):
        os.makedirs(ml_model)
    model_file = os.path.join(ml_model, 'ml_model.sav')

    st.subheader('æ©Ÿå™¨å­¸ç¿’')
    st.markdown(
        f' {"#" * 0} ğŸŒ³ **éš¨æ©Ÿæ£®æ— è¿´æ­¸å™¨** ([RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html))')
    st.markdown(
        f' {"#" * 0} ğŸ’ª **æ¥µé™æ¢¯åº¦æå‡ è¿´æ­¸å™¨** ([XGBRegressor](https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn))')
    st.write('')

    with st.form(key='Form1'):
        col1, col2, col3 = st.columns(3)
        col1.markdown('##### è³‡æ–™ç¯©é¸:')
        city = list(df['city'].unique())
        city_sel = col1.radio('åŸå¸‚ç¯©é¸', tuple(city + ['ä¸é™']), index=city.index('å°åŒ—å¸‚'))
        # typ_sel = col1.radio('å»ºç‰©å‹æ…‹tuple(['å¤§æ¨“(>=11F),è¯å»ˆ( <11F)',ä¸é™']),index=e)
        bypass_1F = col1.radio('æ’é™¤ç‰¹æ®Šæ¨“å±¤ ?', ('æ’é™¤1Fäº¤æ˜“', 'åŒ…å«1Fäº¤æ˜“'), index=0)
        drop_sel = col1.radio('æ’é™¤æ¥µç«¯ç›®æ¨™ ?', ('æ’é™¤æ¥µå€¼(<1%)', 'åŒ…å«'), index=0)
        ano_det = col1.radio('æ’é™¤ç•°å¸¸è³‡æ–™?', ('ç„¡', 'ç•°å¸¸åµæ¸¬ä¸¦æ’é™¤', 'ç•°å¸¸åµæ¸¬'), index=0)

        col2.markdown('##### æ¨¡å‹é¸æ“‡:')
        ml_model = col2.radio('æ¨¡å‹é¸æ“‡', ('RandomForestRegressor', 'XGBRegressor'), index=0)
        tune = col2.radio('èª¿æ ¡æ–¹å¼', ('Manually', 'GridSearch ğŸ¢', 'RandomizedSearch ğŸš§'), index=0)
        tune = tune.split(' ')[0]
        threads = col2.radio('åŸ·è¡Œç·’æ•¸é‡', ('Single-Thread', 'Multi-Threads ğŸ’€'), index=0)
        threads = threads.split(' ')[0]
        n_jobs = 1 if threads == 'Single-Thread' else -1

        col3.markdown('##### è¶…åƒæ•¸èª¿æ ¡:')

        split = col3.slider('æ¸¬è©¦æ¨£æœ¬æ¯”ä¾‹', min_value=0.1, max_value=0.5, step=0.05, value=0.2)

        if len(st.session_state['para']):
            dft_trees = st.session_state['para']['n_estimators']
            dft_depth = st.session_state['para']['max_depth']
        else:
            dft_trees = 700
            dft_depth = 100

        trees = col3.slider('è¦ä½¿ç”¨å¹¾æ£µæ¨¹è¨“ç·´(n_estimators)', min_value=1, max_value=1000, step=10, value=dft_trees)
        max_depth = col3.slider('æ¯é¡†æ¨¹çš„æœ€å¤§æ·±åº¦(max_depth)', min_value=1, max_value=500, step=10, value=dft_depth)
        if ml_model == 'XGBRegressor':
            if 'eta' in st.session_state['para'].keys():
                dft_eta = st.session_state['para']['eta']
            else:
                dft_eta = 0.02

            eta = col3.slider('å­¸ç¿’ç‡ (eta)', min_value=0.01, max_value=0.3, step=0.01, value=dft_eta)

        mse_th = col3.slider('æ¨¡å‹å„²å­˜é–€æª»(MSE)', min_value=0., max_value=9., step=0.1, value=5.)

        st.write('')
        submitted = st.form_submit_button("ä¸Šå‚³")

        if submitted:
            st.write(f'è¨­å®šå®Œæˆ:')
            st.write(city_sel, bypass_1F, drop_sel, ano_det)
            st.write(ml_model, tune)
            if ml_model == 'XGBRegressor':
                st.write('æ¨£æœ¬æ¯”:', split, 'å¹¾æ£µæ¨¹:', trees, 'æ·±åº¦:', max_depth, 'å­¸ç¿’ç‡:', eta)
            else:
                st.write('æ¨£æœ¬æ¯”:', split, 'å¹¾æ£µæ¨¹:', trees, 'æ·±åº¦:', max_depth)
        else:
            st.write('é¸æ“‡åƒæ•¸å¾Œ è«‹æŒ‰ "ä¸Šå‚³" éµ')

    st.write('')
    dic_of_cat = {}

    # is_train = st.button('æ¨¡å‹è¨“ç·´')
    if True:  # if is_train or st.session_state['Train'] == 'done':
        # enc = OneHotEncoder()
        if bypass_1F == 'æ’é™¤1Fäº¤æ˜“':
            df = df[df['ç§»è½‰å±¤æ¬¡'] > 1]  # bypass 1F since it's price is very special
            print(bypass_1F, df.shape[0])

        if city_sel != 'ä¸é™':
            df = df[df['city'] == city_sel]
            print('é¸æ“‡ ' + city_sel, df.shape[0])

        if drop_sel != 'åŒ…å«':  # Remove too few cat ( less than 1% )
            limit = float(drop_sel.split('%')[0][-1]) / 100
            # limit = 0.01
            df['cat'] = df['æ¯åªå–®åƒ¹(è¬)'].apply(lambda x: int(x / 5))
            cat_count = dict(df['cat'].value_counts())
            total = df['cat'].shape[0]
            for k in cat_count.keys():
                if (cat_count[k] / total) < limit:
                    df = df[df['cat'] != k]
                    print(f'æ’é™¤å°‘æ–¼{limit * 100} % ({int(total * limit)}ç­†) çš„ç›®æ¨™: {k * 5}è¬{cat_count[k]} ç­†!')
            drop_num = total - df.shape[0]
            # st.write("')
            # st.markdown(f'{"#" * 5} æ’é™¤åˆ†å°‘æ–¼{limit*100}%çš„ç›®æ¨™:å…±{drop_num}ç­†')
            # st.write('')

        if 'ç„¡' not in ano_det:
            df = fn_anomaly_detection(df.copy(), 100, 1)
            df_ano = df[df['ano']]

            if ano_det == 'ç•°å¸¸åµæ¸¬ä¸¦æ’é™¤':
                df = df.drop(index=df_ano.index)

        grp = df['MRT'].value_counts()
        for idx in grp.index:
            if grp.loc[idx] < 2:
                print(idx, grp.loc[idx])
                df = df[df['MRT'] != idx]

        df.reset_index(drop=True, inplace=True)

        X, df_cat = fn_gen_training_data(df, path)
        y = df[['æ¯åªå–®åƒ¹(è¬)']]

        with st.form(key='Form2'):
            st.markdown('##### è¨“ç·´ç‰¹å¾µé¸æ“‡:')
            features_sel = st.multiselect('ç‰¹å¾µé¸æ“‡:', X.columns,
                                          default=[c for c in X.columns if
                                                   'å»ºæ' not in c and 'è»Šä½' not in c and c != 'MRT'])
            st.write('')
            form2_submitted = st.form_submit_button('é¸æ“‡')

            if form2_submitted:
                st.write(f'é¸æ“‡äº†{len(features_sel)}å€‹ç‰¹å¾µ')
            else:
                st.write('é¸æ“‡ç‰¹å¾µå¾Œ è«‹æŒ‰ "é¸æ“‡" éµ')

        for c in X.columns:
            if X[c].isnull().values.any():
                print(c)
                print(X[c])
                assert False

    st.write('')
    is_train = st.button('æ¨¡å‹è¨“ç·´')
    if is_train or st.session_state['Train'] == 'done':
        X = X[features_sel]
        if drop_sel == 'åŒ…å«':
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split, stratify=X.loc[:, 'MRT'])
        else:
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split, stratify=df['cat'])

        with st.expander(f'ğŸ‘“ æª¢è¦– è³‡æ–™ç¯©é¸'):
            if drop_sel != 'åŒ…å«':
                st.markdown(f'{"#" * 5} æ’é™¤åˆ†ä½ˆå°‘æ–¼{limit * 100} % çš„ç›®æ¨™: å…±{drop_num}ç­†')

            if 'ç„¡' not in ano_det:
                st.markdown(f'{"#" * 5} {ano_det} çš„è³‡æ–™: å…±{df_ano.shape[0]}ç­†')
                df_screen = df_ano[['MRT', 'åœ°å€', 'æ¯åªå–®åƒ¹(è¬)', 'äº¤æ˜“å¹´æœˆæ—¥', 'å‚™è¨»']]
                AgGrid(df_screen)

        with st.expander(f'ğŸ‘“ æª¢è¦– è³‡æ–™åˆ†ä½ˆ'):
            watch = "æ¯åªå–®åƒ¹(è¬)"
            st.markdown(f'{"#" * 5} ç›®æ¨™ *â€œ{watch}"* åœ¨ è¨“ç·´ èˆ‡ æ¸¬è©¦ æ¨£æœ¬çš„åˆ†ä½ˆç‹€æ³:')
            fig = make_subplots(rows=2, cols=1)

            margin = dict(t=10, b=0, l=0, r=0)
            fn_gen_plotly_hist(fig, y_train[watch], 'è¨“ç·´', row=1, margin=margin)
            fn_gen_plotly_hist(fig, y_test[watch], 'æ¸¬è©¦', row=2, margin=margin)
            st.plotly_chart(fig)

            if 'MRT' in X.columns:
                for col_2_check in ['MRT']:  # ,ç§»è½‰å±¤æ¬¡,äº¤æ˜“å¹´
                    st.markdown(f'{"#" * 5} ç‰¹å¾µ *â€œ{col_2_check}â€* åœ¨ è¨“ç·´ èˆ‡ æ¸¬è©¦ æ¨£æœ¬çš„ä½ˆç‹€æ³:')
                    fig = make_subplots(rows=2, cols=1)
                    margin = dict(t=10, b=0, l=0, r=0)
                    fn_gen_plotly_hist(fig, X_train[col_2_check].sort_values(), f'è¨“ç·´:{X_train.shape[0]} ç­†', row=1,
                                       margin=margin)
                    fn_gen_plotly_hist(fig, X_test[col_2_check].sort_values(), f'æ¸¬è©¦: {X_test.shape[0]} ç­†', row=2,
                                       margin=margin)
                    st.plotly_chart(fig)

        if 'MRT' in X.columns:
            X = X.drop(columns='MRT')
            X_train = X_train.drop(columns='MRT')
            X_test = X_test.drop(columns='MRT')

        if tune == 'GridSearch':

            if ml_model == 'XGBRegressor':
                regr_sel = xgb.XGBRegressor()

                param_grid = [
                    {'n_estimators': [400, 500],
                     'max_depth': [40],
                     'eta': [0.01, 0.02]},
                ]
            else:
                regr_sel = RandomForestRegressor()

                param_grid = [
                    {'n_estimators': [600, 800, 1000],
                     'max_depth': [50, 100, 150]},
                    # ('bootstrap': [False],
                    # 'n_estimators': [150,200,259].
                    # 'max_features': [10, X_train.shape[1]]),
                ]

            regr = GridSearchCV(regr_sel,
                                param_grid,
                                cv=10,
                                scoring='neg_mean_squared_error',
                                return_train_score=True,
                                refit=True,
                                n_jobs=n_jobs)
        else:
            if ml_model == 'XGBRegressor':
                regr = xgb.XGBRegressor(max_depth=max_depth,
                                        n_estimators=trees,
                                        objective='reg:squarederror',  # "reg: linear or squarederror"
                                        random_state=42,
                                        eta=eta)

            else:
                regr = RandomForestRegressor(max_depth=max_depth,
                                             n_estimators=trees,
                                             random_state=42,
                                             # criterion='squared_error',
                                             oob_score=True,
                                             max_features='auto')  # "auto", "sqrt", "log2"

        for c in X_train.columns:
            val = X_train[[c]].describe().loc['count', :].values[0]
            if X_train.shape[0] != val:
                print(f'should have {X_train.shape[0]} but feature {c} have {val} valid data only !!! ')
                print(X_train[[c]].describe())
                print(X_train[X_train[c].isna()][c])

        regr.fit(X_train, y_train.values.ravel())

        if tune == 'GridSearch':
            print(regr.best_params_)
            # st.write('')
            col2.text(f'{tune} Result:')
            col2.write(regr.best_params_)
            # st.write('')
            st.session_state['para'] = regr.best_params_

        st.session_state['Train'] = 'done'

        fn_gen_web_ml_eval(ml_model, model_file, regr, X_train, X_test, y_train, y_test, df, mse_th)

        # st.session_state['Train'] = 'done'

    te = time.time()
    dur = round(te - ts, 5)
    print(f'fn_gen_web_ml_train: {dur} ç§’')


def fn_gen_web_ml_eval(ml_model, model_file, regr, X_train, X_test, y_train, y_test, df, mse_th):
    ts = time.time()
    # scores = cross_val_score(regr, x_train, y_train.values.ravel(),cv=5) # st.write(scores)
    pred_train = regr.predict(X_train)
    pred_test = regr.predict(X_test)

    dic_of_metric = {}
    dic_of_metric['æ¨£æœ¬æ•¸'] = [len(y_train), len(y_test)]
    dic_of_metric['R2 score'] = [r2_score(y_train, pred_train), r2_score(y_test, pred_test)]
    dic_of_metric['MSE'] = [mean_squared_error(y_train, pred_train), mean_squared_error(y_test, pred_test)]
    dic_of_metric['MAE'] = [mean_absolute_error(y_train, pred_train), mean_absolute_error(y_test, pred_test)]
    try:
        dic_of_metric['OOB score'] = [regr.oob_score_, np.nan] if ml_model == 'RandomForestRegressor' else [np.nan,
                                                                                                            np.nan]
    except:
        pass

    df_result = pd.DataFrame(dic_of_metric, index=['è¨“ç·´é›†', 'æ¸¬è©¦é›†']).T
    df_result['å·®ç•°'] = df_result['æ¸¬è©¦é›†'] - df_result['è¨“ç·´é›†']

    st.write('')
    is_model_save = st.button('è¨“ç·´ä¸¦å„²å­˜ æ¨¡å‹')
    if is_model_save:
        df_F = pd.DataFrame()
        df_F['Features'] = X_train.columns
        # df_F.to_csv(model_file.replace('.sav', '.csv'), encoding='utf-8-sig', index=False)
        # pickle.dump(regr, open(model_file, 'wb'))
        mse = round(df_result.loc["MSE", "æ¸¬è©¦é›†"], 2)
        st.session_state['Model_Metrics'] = f'æ­¤ {ml_model} æ¨¡å‹åœ¨æ¸¬è©¦è³‡æ–™é›†MSEç‚º {mse}'
        # st.markdown(f'{"#" * 6} {st.session_state["Model_Metrics"]} å·²å„²å­˜ ğŸ’¾ !')
        # st.write(f'save to {model_file}')
        date = datetime.datetime.today().date()
        # date = str(date.month)+str(date.day)
        date_str = str(date.month) if date.month > 9 else '0' + str(date.month)
        date_str += str(date.day) if date.day > 9 else '0' + str(date.day)
        # print(mse)
        if mse < mse_th:
            model_typ = 'xgb' if ml_model == 'XGBRegressor' else 'rf'
            city = 'all_city'
            if len(df['å°åŒ—å¸‚'].unique()) == 1:
                city = 'tpe' if df['å°åŒ—å¸‚'].unique() == 1 else 'new_tpe'

            good_model = model_file.split('.sav')[
                             0] + f'_{city}_{model_typ}_mse_{str(mse).replace(".", "p")}_{date_str}.sav'
            df_F.to_csv(good_model.replace('.sav', '.csv'), encoding='utf-8-sig', index=False)
            pickle.dump(regr, open(good_model, 'wb'))
            st.markdown(f'{"#" * 6} âœ¨ ğŸ¥‡ âœ¨ å”‰å‘¦~ ä¸éŒ¯å–”! æ‰“ä¸Šæ¨™ç±¤ æ”¶è—èµ·ä¾†: ml_{good_model.split("ml_")[-1]} ğŸ’¾ !')
    else:
        # st.write( è¨“ç·´æ¨¡å‹å°šæœªå„²å­˜!
        st.markdown(f'{"#" * 6} è¨“ç·´å‹å°šæœªå„²å­˜ !')

    st.write('')

    st.markdown(f'{"#" * 6} è¨“ç·´çµæœ:')
    st.markdown(f'{"#" * 6} âš† ç‰¹å¾µæ•¸: {len(X_train.columns)} å€‹ (Features)')
    st.markdown(f'{"#" * 6} âš† æ¨£æœ¬æ•¸: {len(X_train) + len(X_test)} ç­† (Instances)')
    st.markdown(f'{"#" * 6} âš† è¨“ç·´æŒ‡æ¨™(Metrics):')

    df_metrics = pd.DataFrame()
    df_metrics['å¯¦éš›åƒ¹æ ¼'] = y_test['æ¯åªå–®åƒ¹(è¬)']
    df_metrics['æ¨¡å‹é ä¼°'] = pred_test
    df_metrics['æ¨¡å‹é ä¼°'] = df_metrics['æ¨¡å‹é ä¼°'].apply(lambda x: round(x, 2))

    df_metrics['èª¤å·®(è¬/åª)'] = df_metrics['æ¨¡å‹é ä¼°'] - df_metrics['å¯¦éš›åƒ¹æ ¼']
    df_metrics['èª¤å·®(è¬/åª)'] = df_metrics['èª¤å·®(è¬/åª)'].apply(lambda x: round(x, 2))
    df_metrics['èª¤å·®(%)'] = round(100 * (df_metrics['æ¨¡å‹é ä¼°'] - df_metrics['å¯¦éš›åƒ¹æ ¼']) / df_metrics['å¯¦éš›åƒ¹æ ¼'], 2)
    df_metrics = df_metrics.reset_index(drop=True)
    df_metrics['å»ºæ¡ˆåç¨±'] = df[[idx in df_metrics.index for idx in df.index]]['å»ºæ¡ˆåç¨±']
    df_metrics['åœ°å€'] = df[[idx in df_metrics.index for idx in df.index]]['åœ°å€']
    # df_metrics['æ¨“å±¤']=x[[idx in df_metrics.index for idx in x.index]][ç§»è½‰å±¤æ¬¡]
    df_metrics['MRT'] = df[[idx in df_metrics.index for idx in df.index]]['MRT']

    del df

    c1, c2 = st.columns(2)
    c1.table(df_result)

    err_th = 2
    df_sel = df_metrics[df_metrics['èª¤å·®(è¬/åª)'].apply(lambda x: abs(x) < err_th)]
    title = f'æ¸¬è©¦èª¤å·®åˆ†ä½ˆ, èª¤å·®<{err_th}è¬çš„é æ¸¬é”{int(100 * df_sel.shape[0] / df_metrics.shape[0])}%'
    fig = make_subplots(rows=1, cols=1, subplot_titles=(title,))

    margin = dict(t=30, b=250, l=0, r=400)
    fig = fn_gen_plotly_hist(fig, df_metrics['èª¤å·®(è¬/åª)'], 'æ¸¬è©¦èª¤å·®åˆ†ä½ˆ(è¬)', margin=margin, opacity=0.7)
    fig = fn_gen_plotly_hist(fig, df_sel['èª¤å·®(è¬/åª)'], 'æ¸¬è©¦èª¤å·®åˆ†ä½ˆ(è¬)', margin=margin, bins=10, barmode='overlay',
                             opacity=0.7)

    c2.plotly_chart(fig)

    try:
        df_imp = pd.DataFrame({'Features': X_train.columns, 'Importance': regr.feature_importances_})
    except:
        df_imp = pd.DataFrame({'Features': X_train.columns, 'Importance': regr.best_estimator_.feature_importances_})

    df_imp = df_imp.sort_values(by='Importance')

    df_top = df_imp.iloc[df_imp.shape[0] - 10:df_imp.shape[0] + 1, :]
    df_bot = df_imp.iloc[:10, :]

    x_data_col = 'Importance'
    y_data_col = 'Features'
    color_col = 'Importance'
    text_col = 'Importance'
    v_or_h = 'h'
    margin = dict(t=0, b=0, l=10, r=15)
    text_fmt = '%{value:.5f}'

    fig_top = fn_gen_plotly_bar(df_top, x_data_col, y_data_col, text_col, v_or_h, margin,
                                color_col=color_col, text_fmt=text_fmt)

    fig_bot = fn_gen_plotly_bar(df_bot, x_data_col, y_data_col, text_col, v_or_h, margin,
                                color_col=color_col, text_fmt=text_fmt, ccs='haline')

    st.markdown(f'{"#" * 5} æ ¹æ“šè¨“ç·´æ¨¡å‹ å½±æˆ¿åƒ¹æœ€ "é‡è¦" çš„{df_top.shape[0]}å€‹å› ç´ æ˜¯?')
    st.plotly_chart(fig_top)

    st.markdown(f'{"#" * 5} æ ¹æ“šè¨“ç·´æ¨¡å‹ å½±æˆ¿åƒ¹è¼ƒ "ä¸é‡è¦" çš„{df_bot.shape[0]}å€‹å› ç´ æ˜¯?')
    st.plotly_chart(fig_bot)

    st.write('æ¸¬è©¦è³‡æ–™é›†çš„æ¨¡å‹é çµæœ(è¬/åª):')
    # st.dataframe(df_metrics)
    AgGrid(df_metrics)

    te = time.time()
    dur = round(te - ts, 5)
    print(f'fn_gen_web_ml_eva:{dur}ç§’')


def fn_gen_web_ml_inference(path, build_typ):
    ts = time.time()

    ml_model = os.path.join(path, r'output/model')
    if not os.path.exists(ml_model):
        os.makedirs(ml_model)

    # model_file = os.path.join(ml_model, 'ml_model.sav')

    model_fdr = ml_model
    models = []
    for i, j, files in os.walk(ml_model):
        for f in files:
            if '.sav' in f and f not in models:
                models.append(f)

    if len(models) > 0:
        st.write('')
        st.subheader('æ¨¡å‹æ¨è«–')

        model_sel = st.selectbox('æ¨¡å‹é¸æ“‡:', models)
        model_typ = model_sel.split('tpe')[-1].split('mse')[0].replace('_', '')
        model_sel = os.path.join(model_fdr, model_sel)

        # load the model from disk
        loaded_model = fn_load_model(model_sel)

        df_F = pd.read_csv(model_sel.replace('.sav', '.csv'), encoding='utf-8-sig')

        dic_of_input = {}
        with st.form('Form2'):
            # å°åŒ—å¸‚åŒ—æŠ•å€è¥¿å®‰è¡—äºŒæ®µ197è™Ÿ
            # å°åŒ—å¸‚åŒ—æŠ•å€å¤§åº¦è·¯ä¸‰æ®µ301å··
            # å°åŒ—å¸‚åŒ—æŠ•å€å¤§åº¦è·¯ä¸‰æ®µ301å··67è™Ÿ
            addr = st.text_input(label='ç‰©ä»¶åœ°å€', value='å°åŒ—å¸‚åŒ—æŠ•å€å¤§åº¦è·¯ä¸‰æ®µ301å··67è™Ÿ')

            addr = fn_addr_handle(addr)
            df_coor_read = fn_house_coor_read()

            # build case = fn_addr_2_build_case(addr)

            geo_info, is_coor_save, is_match, addr_fr_db = fn_get_geo_info(addr, df_coor_read, slp=5)

            st.write(f'é„°è¿‘åœ°å€: {addr_fr_db}') if is_match else None

            # mrt_info, addr_coor, sku_info
            if addr not in df_coor_read.index:
                dic_of_coor = {addr: (geo_info['coor']['lat'], geo_info['coor']['log'])}
                df_coor = pd.DataFrame(dic_of_coor, index=['lat', 'lon'])
                df_coor = df_coor.T

                dic_of_dist = fn_get_admin_dist(addr)
                for k in dic_of_dist.keys():
                    df_coor[k] = dic_of_dist[k]

                df_coor_save = df_coor_read.append(df_coor)
                if is_coor_save:
                    fn_house_coor_save(df_coor_save)

            dic_of_input['å°åŒ—å¸‚'] = 1 if 'å°åŒ—å¸‚' in addr else 0

            for d in geo_info.keys():
                for k in geo_info[d].keys():
                    dic_of_input[k] = geo_info[d][k]

            ave_path = dic_of_path['database']
            df_sku_ave = pd.read_csv(os.path.join(ave_path, 'SKU_ave.csv'), index_col='sku_name')
            df_mrt_ave = pd.read_csv(os.path.join(ave_path, 'MRT_ave.csv'), index_col='MRT')
            df_dist_ave = pd.read_csv(os.path.join(ave_path, 'DIST_ave.csv'), index_col='é„‰é®å¸‚å€')

            mrt = dic_of_input['MRT']
            dic_of_input['MRT_ave'] = df_mrt_ave.loc[mrt, 'æ¯åªå–®åƒ¹(è¬)']

            sku = dic_of_input['sku_name']
            sku = sku if sku in df_sku_ave.index else fn_get_neighbor(sku, df_sku_ave.index)
            dic_of_input['SKU_ave'] = df_sku_ave.loc[sku, 'æ¯åªå–®åƒ¹(è¬)']
            dist = addr.split('å¸‚')[-1].split('å€')[0] + 'å€'
            dic_of_input['DIST_ave'] = df_dist_ave.loc[dist, 'æ¯åªå–®åƒ¹(è¬)']

            dic_of_input['ç·¯åº¦'] = dic_of_input.pop('lat')
            dic_of_input['ç¶“åº¦'] = dic_of_input.pop('log')

            c1, c2, c3 = st.columns(3)
            dic_of_input['å»ºç‰©åªæ•¸'] = c1.text_input(label='å»ºç‰©åªæ•¸(ä¸å«è»Šä½):', value=24)
            dic_of_input['è»Šä½åªæ•¸'] = c2.text_input(label='è»Šä½åªæ•¸:', value=2.21)
            dic_of_input['åœŸåœ°åªæ•¸'] = c3.text_input(label='åœŸåœ°åªæ•¸', value='æœªä½¿ç”¨')

            c1, c2, c3, c4 = st.columns(4)
            dic_of_input['äº¤æ˜“å¹´'] = c1.slider('äº¤æ˜“å¹´(æ°‘åœ‹)', min_value=100, max_value=130, step=1, value=110)
            dic_of_input['ç§»è½‰å±¤æ¬¡'] = c2.slider('äº¤æ˜“æ¨“å±¤', min_value=2, max_value=40, step=1, value=14)
            dic_of_input['ç¸½æ¨“å±¤æ•¸'] = c3.slider('å»ºç‰©ç¸½æ¨“å±¤', min_value=2, max_value=40, step=1, value=15)
            dic_of_input['å±‹é½¡'] = c4.slider('å±‹é½¢', min_value=0, max_value=20, step=1, value=0)

            c1, c2, c3, c4, c5 = st.columns(5)
            dic_of_input['å¹¾æˆ¿'] = c1.radio('å¹¾æˆ¿?', (1, 2, 3, 4, 5, 6), index=2)
            dic_of_input['å¹¾å»³'] = c2.radio('å¹¾å»³?', (1, 2, 3, 4, 5, 6), index=0)
            dic_of_input['å¹¾è¡›'] = c3.radio('å¹¾è¡›?', (1, 2, 3, 4, 5, 6), index=1)
            dic_of_input['ä¸»è¦å»ºæ'] = c4.radio('å»ºç¯‰çµæ§‹', fn_get_categories(path, 'ä¸»è¦å»ºæ'))
            dic_of_input['è»Šä½é¡åˆ¥'] = c5.radio('è»Šä½é¡åˆ¥', fn_get_categories(path, 'è»Šä½é¡åˆ¥'),
                                            index=fn_get_categories(path, 'è»Šä½é¡åˆ¥').index('å¡é“æ©Ÿæ¢°'))

            submitted = st.form_submit_button("ä¸Šå‚³")

            if submitted:
                st.write(f'è¨­å®šå®Œæˆ')
            else:
                st.write("é¸æ“‡åƒæ•¸å¾ŒæŒ‰ä¸Šå‚³éµ")

            st.session_state['pred_para'] = dic_of_input
            # st.write(st.session_state['pred_para'l)

        df_input = pd.DataFrame(dic_of_input, index=[0])
        X, df_cat = fn_gen_training_data(df_input, path, is_inference=True, df_F=df_F)
        # st.write(X)

        is_pred = st.button('click to predict')
        if is_pred:
            pred = loaded_model.predict(X)
            if model_typ == 'rf':
                trees, conf = fn_gen_model_confidence(loaded_model, X)

            price = round(pred[0], 2)
            area = float(dic_of_input["å»ºç‰©åªæ•¸"])
            total = int(price * area)

            with st.expander(f'Feature Number : {X.shape[1]}'):
                st.write(dict(X.iloc[0, :]))

            df_map = X.copy()
            df_map['é ä¼°å–®åƒ¹'] = [f'é ä¼°å–®åƒ¹: {str(price)} è¬åª']
            df_map['é„°è¿‘æ·é‹ç«™'] = [df_input['MRT'].values]
            df_map['æ·é‹é€šå‹¤æ™‚é–“'] = [str(X['MRT_Commute_Time_UL'].values[0]) + ' åˆ†']
            df_map['æ·é‹ç«™è·é›¢'] = [str(X['MRT_DIST'].values[0]) + ' å…¬å°º']
            df_map['é„°è¿‘å°å­¸'] = [df_input['sku_name'].values]
            df_map['å°å­¸è·é›¢'] = [str(X['sku_dist'].values[0]) + ' å…¬å°º']
            df_map['å°å­¸äººæ•¸'] = [str(int(X['sku_total'].values[0])) + ' äºº']

            title = addr
            hover_data = ['é„°è¿‘æ·é‹ç«™', 'æ·é‹ç«™è·é›¢', 'æ·é‹é€šå‹¤æ™‚é–“', 'é„°è¿‘å°å­¸', 'å°å­¸è·é›¢', 'å°å­¸äººæ•¸']

            build_case = fn_addr_2_build_case(addr)
            if build_case != 'No_build_case_found':
                df_map['å»ºæ¡ˆåç¨±'] = [build_case]
                title += f' ({build_case})'
                hover_data = ['å»ºæ¡ˆåç¨±'] + hover_data

            # "open-street-map", "white-bg", "carto-positron", "stamen-terrain"
            fig = fn_gen_plotly_map(df_map, title, 'é ä¼°å–®åƒ¹', hover_data, 'carto-positron', zoom=15)

            st.subheader(f'æ¨¡å‹é ä¼°:')
            st.markdown(f'{"#" * 4} ğŸ”® é ä¼°å–®åƒ¹: {str(price)} è¬/åª')
            st.markdown(f'{"#" * 4} ğŸ”® é ä¼°ç¸½åƒ¹: {total} è¬+è»Šä½åƒ¹æ ¼')
            if model_typ == 'rf':
                show = 'ğŸ‘' if conf[0] > 96 else 'ğŸ‘'
                st.markdown(f'{"#" * 4} ğŸ”® ä¿¡å¿ƒæŒ‡æ¨™: {conf[0]} {show}')

            st.plotly_chart(fig)

            if model_typ == 'rf':
                fn_gen_model_explain(X.copy(), loaded_model)

        is_rf = model_typ == 'rf'
        fn_gen_pred(path, loaded_model, model_sel, df_F, build_typ, is_rf)
    else:
        st.write(f'No models found in {model_fdr}')
        st.write('è«‹å…ˆé€²è¡Œ"æ¨¡å‹è¨“ç·´')

    te = time.time()
    dur = round(te - ts, 5)
    print(f'fn_gen_web_inference: {dur} ç§’')


def fn_gen_web_init(path, page=None):
    print('fn_gen_web_init start')
    path_output = os.path.join(path, r'output')
    path_output = os.path.join(path_output, r'house_all.csv')
    print(path_output)
    if not os.path.exists(path_output):
        assert path_output + ' NOT existed !!!'
    # Initialization
    if 'Train' not in st.session_state:
        st.session_state['Train'] = 'not_yet'

    if 'Model_Metrics' not in st.session_state:
        st.session_state['Model_Metrics'] = 'init'

    if 'para' not in st.session_state:
        st.session_state['para'] = {}

    if 'pred_para' not in st.session_state:
        st.session_state['pred_para'] = {}

    # print(f'session_state: {st.session_state}')
    df = fn_get_house_data(path_output)
    df = fn_cln_house_data(df.copy())

    if page == 'train':
        cat_features = ['é„‰é®å¸‚å€', 'ä¸»è¦å»ºæ', 'è»Šä½é¡åˆ¥', 'MRT']
        for cat in cat_features:
            df_cat = pd.DataFrame(columns=[cat], data=sorted(list(df[cat].unique())))
            file = os.path.join(path, f'output\\Feature_{cat}.csv')
            df_cat.to_csv(file, encoding='utf-8-sig')

    print('fn_gen_web_init done')
    return df.copy()


def fn_gen_web_ref():
    st.subheader('æ•¸æ“šä¾†æº:')
    st.write("- å¯¦åƒ¹ç™»éŒ„: [å…§æ”¿éƒ¨ - ä¸å‹•ç”¢æˆäº¤æ¡ˆä»¶ è³‡æ–™ä¾›æ‡‰ç³»çµ±(æ¯æœˆ1ã€11ã€21æ—¥ç™¼å¸ƒ)](https://plvr.land.moi.gov.tw/DownloadOpenData)")
    st.write("- é‹è¼¸è³‡æ–™æµé€šæœå‹™å¹³å°: [äº¤é€šéƒ¨ - TDX(Transport Data eXchange)](https://tdx.transportdata.tw/)")
    st.write("- åº§æ¨™è³‡è¨Š: [å°ç£é›»å­åœ°åœ–æœå‹™ç¶²](https://www.map.com.tw/)")
    st.write("- åº§æ¨™è³‡è¨Š: [TGOSå…¨åœ‹é–€ç‰Œåœ°å€å®šä½æœå‹™](https://www.tgos.tw/tgos/Web/AddrssTGOS_Address.aspx)")
    st.write("- åœ‹åœŸè³‡è¨Šåœ–è³‡æœå‹™å¹³è‡º: [Taiwan Geospatial One Stop. ç¨±TGOSå¹³è‡º](https://www.tgos.tw/tgos/web/tgos_home.aspx)")
    st.write("- æ·é‹ - å„ç«™åœ°å€: [å°åŒ—æ·é‹ - è·¯ç¶²åœ– å„ç«™è³‡è¨ŠåŠæ™‚åˆ»è¡¨](https://www.metro.taipei/cp.aspx?n=91974F2B13D997F1)")
    st.write("- æ·é‹ - è¡Œé§›æ™‚é–“: [å°åŒ—æ·é‹ - å–®ä¸€è»Šç«™è‡³æ‰€æœ‰è»Šç«™æ™‚é–“](https://web.metro.taipei/pages/tw/ticketroutetimesingle/068)")
    st.write("- æ·é‹ - äººæ•¸çµ±è¨ˆ: [æ”¿åºœè³‡æ–™é–‹æ”¾å¹³å° - å°åŒ—æ·é‹æ¯æ—¥åˆ†æ™‚å„ç«™ODæµé‡çµ±è¨ˆè³‡æ–™](https://data.gov.tw/dataset/128506)")
    st.write(
        "- å°å­¸ - äººæ•¸çµ±è¨ˆ: [çµ±è¨ˆè™• - å„ç´šå­¸æ ¡åŸºæœ¬è³‡æ–™](https://depart.moe.edu.tw/ed4500/News.aspx?n=5A930C32CC6C3818&sms=91B3AAE8C6388B96)")
    st.write("- å°å­¸ - å„æ ¡åœ°å€(å°åŒ—å¸‚): [æ”¿åºœè³‡æ–™é–‹æ”¾å¹³å° - å°åŒ—å¸‚å„ç´šå­¸æ ¡åˆ†å¸ƒåœ–](https://data.gov.tw/dataset/121225)")
    st.write("- å°å­¸ - å„æ ¡åœ°å€(æ–°åŒ—å¸‚): [æ”¿åºœè³‡æ–™é–‹æ”¾å¹³å° - æ–°åŒ—å¸‚å­¸æ ¡é€šè¨Šè³‡æ–™](https://data.gov.tw/dataset/123020)")
    st.write("- æ­´å²åˆ©ç‡: [è‡ºç£éŠ€è¡Œå­˜æ”¾æ¬¾åˆ©ç‡æ­·å²è³‡æ–™è¡¨](https://www.cbc.gov.tw/tw/public/data/a13rate.xls)")
    st.write("- æ­·å²åŒ¯ç‡: [è‡ºç£æœŸè²¨äº¤æ˜“æ‰€ - æ¯æ—¥å¤–å¹£å‚è€ƒåŒ¯ç‡æŸ¥è©¢](https://www.taifex.com.tw/cht/3/dailyFXRate)")
    st.write("- ç¶“æ¿Ÿæˆé•·: [è¡Œæ”¿é™¢ä¸»è¨ˆç¸½è™• - ä¸­è¯æ°‘åœ‹çµ±è¨ˆè³‡è¨Šç¶²]")
    st.write("- äººå£æ™®æŸ¥: [è¡Œæ”¿é™¢ä¸»è¨ˆç¸½è™• - 109å¹´æ™®æŸ¥åˆæ­¥çµ±è¨ˆçµæœè¡¨](https://www.stat.gov.tw/ct.asp?mp=4&xItem=47698&ctNode=549)")
    st.write("- å–®é»åæ¨™å›å‚³è¡Œæ”¿å€: [æ”¿åºœè³‡æ–™é–‹æ”¾å¹³å° - åæ¨™å›å‚³è¡Œæ”¿å€API](https://data.gov.tw/dataset/101898)")
    st.write("- é„‰é®å¸‚å€ç•Œç·š: [æ”¿åºœè³‡æ–™é–‹æ”¾å¹³å° - æˆ‘åœ‹å„é„‰(é®Â·å¸‚ã€å€)è¡Œæ”¿å€åŸç•Œç·šåœ–è³‡](https://data.gov.tw/dataset/441)")
    st.write("- æ‘é‡Œç•Œåœ–: [æ”¿åºœè³‡æ–™é–‹æ”¾å¹³å° - å„ç¸£å¸‚æ‘(é‡Œ)ç•Œ](https://data.gov.tw/dataset/7438)")

    st.write("")
    st.subheader('åƒè€ƒç¶²ç«™:')
    st.write("- å¯¦åƒ¹ç™»éŒ„ç¶²ç«™: [æ¨‚å±…](https://www.leju.com.tw/)")
    st.write("- å¯¦åƒ¹ç™»éŒ„ç¶²ç«™: [å¯¦åƒ¹ç™»éŒ„æ¯”åƒ¹ç‹](https://community.houseprice.tw/building/118031)")
    st.write("- æˆ¿åƒ¹é æ¸¬ç¶²ç«™: [ä¸­ä¿¡éŠ€è¡Œ æ™ºæ…§åƒ¹å¹³å°](https://www.ctbcbank.com/contet/dam/minisite/long/loan/ctbc-mortgage/index.html)")
    st.write("- æˆ¿åƒ¹é æ¸¬ç¶²ç«™: [å¥½æ™‚åƒ¹House+(åˆ©ç”¨çµ±è¨ˆå­¸ã€æ•¸å­¸åŠäººå·¥æ™ºæ…§(AI)æ¼”ç®—æ³•,ç®—å‡ºä¸å‹•ç”¢åƒ¹å€¼)](https://www.houseplus.tw/)")
    st.write("- æˆ¿åƒ¹æŒ‡æ•¸: [åœ‹ç«‹æ¸…è¯å¤§å­¸ å®‰å¯Œé‡‘èå·¥ç¨‹ç ”ç©¶ä¸­å¿ƒ](https://aife.site.nthu.edu.tw/p/404-1389-220340.php)")

    st.write('')
    st.subheader('ç›¸é—œç«¶è³½:')
    st.write("- äº¤é€šéƒ¨: [äº¤é€šæ•¸æ“šå‰µæ–°æ‡‰ç”¨ç«¶è³½](https://tdx-contest.tca.org.tw) [TDXäº¤é€šè³‡æ–™è‚²æˆç¶²](https://startup.transportdata.tw/)")
    st.write("- ç‰å±±äººå·¥æ™ºæ…§å…¬é–‹æŒ‘æˆ°è³½2019å¤å­£è³½:[å°ç£ä¸å‹•ç”¢AIç¥é æ¸¬](https://tbrain.trendmicro.com.tw/competitions/Details/6)")
    st.write("- ç¶“æ¿Ÿéƒ¨ä¸­å°ä¼æ¥­è™•:[2021åŸå¸‚æ•¸æ“šå¯¦å¢ƒè³½](https://data.startupterrace.tw/data-contest)")

    st.write("")
    st.subheader('å°ˆåˆ©:')
    st.write("- æ™ºèƒ½ä¸å‹•ç”¢ä¼°åƒ¹å°ˆåˆ©: [ä¸­è¯æ°‘åœ‹å°ˆåˆ©è³‡è¨Šæª¢ç´¢ç³»çµ±](https://twpat2.tipo.gov.tw/twpatc/twpatkm?@@642176895)")


def fn_gen_web_tools():
    st.write("")
    st.subheader('æ©Ÿå™¨å­¸ç¿’:')
    st.write(
        "- æ•™ç§‘æ›¸: [Hands on Machine Learning - ç¬¬äºŒç« : ç¾åœ‹åŠ å·æˆ¿åƒ¹é æ¸¬](https://nbviewer.org/github/DeqianBai/Hands-on-Machine-Learning/blob/master/02_Housing.ipynb)")
    st.write(
        "- ç¢©å£«è«–æ–‡: [æ·¡æ±Ÿå¤§å­¸ç¢©å£«åœ¨è·å°ˆç­ æ‡‰ç”¨äººå·¥æ™ºæ…§æ–¼æˆ¿åƒ¹é æ¸¬æ¨¡å‹ç ”ç©¶èˆ‡åˆ†æ(2019)](https://etds.lib.tku.edu.tw/ETDS/Home/Detail/U0002-2608201910580000)")
    st.write("- æ¨¡å‹æ‡‰ç”¨: [å¾®è»Ÿæ™‚ç©ºé æ¸¬æ¨¡å‹ FOST(Forecasting open source tool)]")

    st.write('')
    st.subheader('ç¶²é è£½ä½œ:')
    st.write("- ç´”Pythonçš„æ¥µé€Ÿç¶²é è£½ä½œå¥—ä»¶: [Streamlit](https://streamlit.io/)")
    st.write(
        "- Streamlit multi page framework: [streamlit-multiapps](https://github.com/upraneelnihar/streamlit-multiapps)")
    st.write("- ç•«æ–‡å­— è¡¨æƒ…ç¬¦è™Ÿ: [Emojipedia](https://emojipedia.org/)")

    st.write('')
    st.subheader('å‡½å¼åº«:')
    st.write("- è‡ªå‹•åŒ–è³‡æ–™åˆ†æ: [DataPrep](https://docs.dataprep.ai/user_guide/user_guide.html)")
    st.write("- ç¶²é çˆ¬èŸ²è‡ªå‹•åŒ–: [Selenium](https://www.selenium.dev/documentation/webdriver/)")
    st.write("- å¥½çœ‹çš„ç¶²é è¡¨æ ¼: [Streamlit-Aggrid](https://github.com/PablocFonseca/streamlit-aggrid)")
    st.write("- äº’å‹•å¼ç¶²é åœ–è¡¨: [Plotly](https://plotly.com/python/)")
    st.write("- åº§æ¨™çš„è·é›¢è¨ˆç®—: [GeoPy](https://geopy.readthedocs.io/en/stable/)")
    st.write("- åœ°ç†ç©ºé–“å‡½å¼åº«: [GeoPandas](https://geopandas.org/en/stable/)")
    st.write("- ä¸­æ–‡è½‰é˜¿æ‹‰ä¼¯æ•¸å­—: [cn2an](https://github.com/Ailln/cn2an)")
    st.write("- ç€‘å¸ƒåœ–: [waterfall_chart](https://github.com/chrispaulca/waterfall)")
    st.write("- è¡Œäº‹æ›†: [workalendar](https://github.com/workalendar/workalendar)")

    st.write('')
    st.subheader('å…¶å®ƒå·¥å…·:')
    st.write("- åœ–è½‰æ–‡å­—: [LINE OCR](https://www.tech-girlz.com/2021/01/line-ocr.html)")
    st.write("- åœ–è½‰CSV: [èª è¯OCR](https://zhtw.109876543210.com/)")


def fn_chrome_96_workaround():
    # st.write('<style>div{font-weight: normal;}</style>', unsafe_allow_html=True)
    pass


def fn_app(page='data'):
    print(f'fn_app() start, page = {page}')
    fn_chrome_96_workaround()
    # st.legacy_caching.clear_cache()

    st.sidebar.header(f'ğŸ” è³‡è¨Šç¯©é¸:\n')
    year_sel = st.sidebar.slider('äº¤æ˜“å¹´(æ°‘åœ‹)', min_value=100, max_value=111, value=(100, 111))
    c1, c2 = st.sidebar.columns(2)
    sel = c1.selectbox('äº¤æ˜“é¡åˆ¥', ['é å”®å±‹', 'ä¸­å¤å±‹'], index=0)
    root = dic_of_path['root']
    path = os.path.join(root, r'pre_sold_house') if sel == 'é å”®å±‹' else os.path.join(root, r'pre_owned_house')
    ml_model = os.path.join(path, r'output\model')

    if not os.path.exists(ml_model):
        os.makedirs(ml_model)

    # page = 'eda'
    if page == 'eda':
        df = fn_gen_web_init(path)
        df = df[df['äº¤æ˜“å¹´'].apply(lambda x: year_sel[0] <= x <= year_sel[1])]
        build_typ = c2.selectbox('å»ºç‰©å‹æ…‹', ['å¤§æ¨“', 'è¯å»ˆ', 'ä¸é™'], index=0)
        df = df[df['å»ºç‰©å‹æ…‹'] == build_typ] if build_typ != 'ä¸é™' else df

        c1, c2 = st.sidebar.columns(2)
        city = c1.selectbox('åŸå¸‚', ['å°åŒ—å¸‚', 'æ–°åŒ—å¸‚', 'ä¸é™'], index=0)
        is_tpe = city == 'å°åŒ—å¸‚'
        df = df[df['å°åŒ—å¸‚'] == is_tpe] if city != 'ä¸é™' else df

        d = c2.selectbox('é„‰é®å¸‚å€', ['ä¸é™'] + df['é„‰é®å¸‚å€'].unique().tolist(), index=0)
        df = df[df['é„‰é®å¸‚å€'] == d] if d != 'ä¸é™' else df

        land_typ = st.sidebar.selectbox('åœŸåœ°åˆ†å€', ['ä¸é™', 'ä½', 'å•†'], index=0)
        df = df[df['éƒ½å¸‚åœŸåœ°ä½¿ç”¨åˆ†å€'] == land_typ] if land_typ != 'ä¸é™' else df

        fn_gen_web_eda(df)

    elif page == 'train':
        df = fn_gen_web_init(path, page=page)
        df = df[df['äº¤æ˜“å¹´'].apply(lambda x: year_sel[0] <= x <= year_sel[1])]
        build_typ = c2.selectbox('å»ºç‰©å‹æ…‹', ['å¤§æ¨“', 'è¯å»ˆ', 'ä¸é™'], index=0)
        df = df[df['å»ºç‰©å‹æ…‹'] == build_typ] if build_typ != 'ä¸é™' else df

        land_typ = st.sidebar.selectbox('åœŸåœ°åˆ†å€', ['ä¸é™', 'ä½', 'å•†'], index=0)
        df = df[df['éƒ½å¸‚åœŸåœ°ä½¿ç”¨åˆ†å€'] == land_typ] if land_typ != 'ä¸é™' else df

        fn_gen_web_ml_train(df, path)

    elif page == 'inference':
        build_typ = c2.selectbox('å»ºç‰©å‹æ…‹', ['å¤§æ¨“', 'è¯å»ˆ', 'ä¸é™'], index=0)
        fn_gen_web_ml_inference(path, build_typ)

    elif page == 'reference':
        fn_gen_web_ref()

    elif page == 'tools':
        fn_gen_web_tools()

    else:
        st.write(f' page: {page} unhandle yet !!!')

    print(f'fn_app() done, page = {page}')
